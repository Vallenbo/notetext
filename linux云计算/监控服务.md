

# Zabbix集中监控系统

官方文档  [Zabbix 使用手册](https://www.zabbix.com/documentation/6.0/zh/manual)

## 基本概述

zabbix是一个监控软件，其可以监控各种网络参数，保证企业服务架构安全运营，同时支持灵活的告警机制，可以使得运维人员快速定位故障、解决问题。zabbix支持分布式功能，支持复杂架构下的监控解决方案，也支持web页面，为主机监控提供了良好直观的展现。

## 架构构成

zabbix主要由以下5个组件构成：
1、Server
zabbix server是zabbix的核心组件，server内部存储了所有的配置信息、统计信息和操作信息。zabbix agent会向zabbix server报告可用性、完整性及其他统计信息。

2、web页面
web页面也是zabbix的一部分，通常和zabbix server位于一台物理设备上，但是在特殊情况下也可以分开配置。web页面主要提供了直观的监控信息，以方便运维人员监控管理。

3、数据库
zabbix数据库内存储了配置信息、统计信息等zabbix的相关内容。

4、proxy
zabbix proxy可以根据具体生产环境进行采用或者放弃。如果使用了zabbix proxy，则其会替代zabbix server采集数据信息，可以很好的分担zabbix server的负载。zabbix proxy通常运用与架构过大、zabbix server负载过重，或者是企业设备跨机房、跨网段、zabbix server无法与zabbix agent直接通信的场景。

5、Agent
zabbix agent通常部署在被监控目标上，用于主动监控本地资源和应用程序，并将监控的数据发送给zabbix server。

## 监控对象

zabbix支持监控各种系统平台，包括Linux和Windows等主流操作系统，也可以借助SNMP或者是SSH协议监控路由交换设备。

zabbix如果部署在服务器上，可以监控其CPU、内存、网络性能等硬件参数，也可以监控具体的服务或者应用程序、服务运行情况及性能。

**硬件监控**：Zabbix IPMI Interface ，通过IPMI接口进行监控，我们可以通过标准的IPMI硬件接口，监控被监控对象的物理特征，比如电压、温度、风扇状态、电源状态等。
**系统监控**：Zabbix Agent Interface ，通过专用的代理程序进行监控，与常见的master/agent模型类似，如果被监控对象支持对应的agent，推荐首选这种方式。
**Java监控**：Zabbix JMX Interface ，通过JMX进行监控，JMX（java management extensions，即java管理扩展），监控JVM虚拟机时，使用这种方法是非常不错的选择。
**网络设备监控**：Zabbix SNMP Interface ，通过SNMP协议与被监控对象进行通信，SNMP协议的全称为simple network management protocol，被译为简单网络管理协议，通常来说，我们无法在路由器、交换机这种硬件上安装agent，但是这些硬件都支持SNMP协议。
**应用服务监控**：Zabbix Agent UserParameter
**MySQL数据库监控**：percona-monitoring-plulgins   
**URL监控**：Zabbix Web 监控

## 常用术语

zabbix的学习需要掌握一些zabbix的常用术语，zabbix常用术语列举如下：
1、主机（host）
要监控的设备，可以由IP或者是主机名（必须可解析）指定。

2、主机组（host group）
主机的逻辑容器，包含主机和模板，主机组通常在给用户或者是用户组指派监控权限时使用。

3、监控项（item）
一个特定监控指标的相关数据，比如内存的大小、CPU的使用率，甚至是服务的运行状态等等。监控项数据来源于被监控对象，并且每个监控项都由一个key来标识。

4、触发器（trigger）
一个表达式，用于评估监控项的值是否在合理的范围内。当接收的值超出触发器的规定时，就被认为是故障，如果超出后再次符合，就被认为是正常。

5、事件（event）
触发器触发的一个特定事件，或者是zabbix定义的一个自动上线注册主机的事件。

6、动作（action）
指根据配置，zabbix对于触发器触发的特定事件进行处理的具体措施，如执行某个脚本，或者是向管理员邮箱发送邮件等等。

7、报警升级（escalation）
发送警报或者是执行远程命令的自定义方案。

8、媒介（media）
发送通知（告警）的手段，如微信、邮件、钉钉等等。

9、通知（notification）
通过指定的媒介，向用户发送的有关事件的信息。

10、远程命令（remote command）
指运维人员提前写好的命令，可以让被监控主机在触发事件后执行。

11、模板（template）
用于快速定义被监控主机的预设条目集合，通常包括了监控项、触发器、应用等，模板可以直接链接至某个主机。

12、应用（application）
一组监控项的集合。

13、web场景（web scennario）
用于检测web站点可用性的一个或多个HTTP请求。

14、前端（frontend）
zabbix的web接口。

这些术语，我们都会在后文中直接使用而不过多赘述，在企业技术交流中也会经常使用。


## 工作流程

Zabbix在进行监控时，zabbix客户端要安装在被监控设备上，负责定期收集数据，并将其发送给zabbix服务端；zabbix服务端要安装在监控设备上，其将zabbix客户端发送的数据存储的数据库中，zabbix web根据数据在前端进行展示和绘图。

==zabbix的数据收集分为两种模式==：

**1、主动模式**
zabbix客户端主动向zabbix server请求监控项列表，并主动将监控项内需要的数据提交给zabbix server。

**2、被动模式**
zabbix server向 agent 请求获取监控项的数据，zabbix agent返回数据。
由此可以看出zabbix的主动和被动模式是以zabbxi客户端为基准的。

<img src="./assets/image-20231012151645634.png" alt="image-20231012151645634" style="zoom: 33%;" />



## 进程详解

在默认的情况下，zabbix有6个工作进程；分别是 zabbix_agentd，zabbix_get，zabbix_proxy，zabbix_sender，zabbix_server 和 zabbix_gateway。

其中，zabbix_java_gateway是可选进程。这6个进程的作用如下：
**1、zabbix_agentd**
zabbix-agentd为zabbix客户端守护进程 ，主要负责收集客户端监控项数据。

**2、zabbix_server**
zabbix_server为zabbix服务端守护进程，主要负责收集zabbix客户端数据。（端口为10051）

**3、zabbix_proxy**
zabbix_proxy是zabbix的代理程序，其功能类似于server，作用上类似于一个中转站，最终会把收集的数据再次提交给zabbix_server。

**4、zabbix_get**
zabbix_get作为zabbix工具，通常运行在zabbix_server或者zabbix_proxy上，用于远程获取客户端信息，通常用于排错。

**5、zabbix_sender**
zabbix_sender也是zabbix的一个工具，通常运行在zabbix的客户端，用于耗时比较长的检查，其作用是主动发送数据。

**6、zabbix_java_gateway**
zabbix_java_gateway是zabbix2.0以后引入的新功能，可以用于JAVA方面的设备；但是只能主动获取数据，而不能被动获取数据。

## 监控框架

在实际的工作环境中，根据网络环境和监控的规模不同，zabbix一共有三种框架，分别是server_client架构、master_node_client架构和server_proxy_client架构。

1、server_client架构

zabbix最简单的架构，监控设备和被监控设备之间直接相连，zabbix_server 和 zabbix_client 之间直接进行数据交互。

2、zabbix_proxy_client架构

proxy是连接 server 和 client 之间的桥梁，其本身不存放数据，只是将zabbix_agent端发来的数据暂存，然后再提交给server。这种架构一般用于跨机房、跨网络的中型网络架构。

在server_proxy_client架构中，server设备的宕机会导致整个系统瘫痪而无法正常工作。

3、master_node_client架构

master_node_client架构是zabbix最复杂的架构。一般用于跨机房、跨网络、监控设备较多的大型网络架构。与server_proxy_client架构相比，master_node_client架构的主要区别在于node与proxy上.

在master_node_client架构中，每个node可以理解为一个小的server端，在自己的配置文件和数据库，node下游可以直接连接client，也可以再次经过proxy代理后连接client。

在master_node_client架构中，master设备宕机不会影响node节点的正常工作。

### 三种架构模式的架构图如下：

<img src="./assets/7f719704eea845e4ace3b2a25c9662d2.png" alt="img" style="zoom:50%;" />

### 每个模块的工作职责：

1、Zabbix_Server：zabbix_server作为核心组件，用来获取agent存活情况和监控数据。所有的配置、统计、操作数据均通过server进行存取到database；

2、Zabbix_Database：用户存储所有的zabbix的配置信息、监控数据的数据库；

3、Zabbix_Web：zabbix的web界面，管理员通过web界面管理zabbix配置以及查看zabbix相关监控信息，通常与zabbix_server运行在同一台主机上，也可以单独部署在独立的服务器上；

4、Zabbix_Agent：部署在被监控主机上，负责收集被监控主机的数据，并发送给servre端或者proxy端；

5、Zabbix_Proxy：通常用于分布式监控，代理zabbix_server收集部分被监控的数据并统一发送给server端；（==通常大于500台主机需要使用==）

Zabbix Server、Proxy、Agent都有自己的配置文件以及log文件，重要的参数需要在这里配置，后面会详细说明。 



## docker容器化部署

本次使用docker搭建zabbix的组合是mysql+docker+zabix-server

确定zabbix数据挂载位置

```sh
docker volume create zabbix-mysql-data
docker volume create zabbix-mysql-log
docker volume create zabbix-server-conf
docker volume create zabbix-server-data
```

### 1 先安装数据库mysql

```sh
docker run --name zabbix-mysql-server --hostname zabbix-mysql-server \
-e MYSQL_ROOT_PASSWORD="kylin123." \
-e MYSQL_USER="zabbix" \
-e MYSQL_PASSWORD="kylin123." \
-e MYSQL_DATABASE="zabbix" \
-v zabbix-mysql-data:/var/lib/mysql \
-v zabbix-mysql-log:/var/log/mysql \
-p 3306:3306 \
-d mysql:8.0 \
--character-set-server=utf8 --collation-server=utf8_bin
```

出现报错：ERROR 1419 (HY000) at line 9: You do not have the SUPER privilege and binary logging is enabled (you *might* want to use the less safe log_bin_trust_function_creators variable）

解决办法：

```mysql
mysql> SET GLOBAL log_bin_trust_function_creators = 1;
mysql> flush privileges;
```



### 2 创建zabbix-server

```sh
docker run  --name zabbix-server-mysql --hostname zabbix-server-mysql \
--link zabbix-mysql-server:mysql \
-e DB_SERVER_HOST="mysql" \
-e MYSQL_USER="zabbix" \
-e MYSQL_DATABASE="zabbix" \
-e MYSQL_PASSWORD="kylin123." \
-v zabbix-server-conf:/etc/zabbix \
-v zabbix-server-data:/var/lib/zabbix \
-p 10051:10051 \
-d zabbix/zabbix-server-mysql
```

### 3 最后web-nginx

```sh
最后安装zabbix-web-nginx
docker run --name zabbix-web-nginx-mysql --hostname zabbix-web-nginx-mysql \
--link zabbix-mysql-server:mysql \
--link zabbix-server-mysql:zabbix-server \
-e DB_SERVER_HOST="mysql" \
-e MYSQL_USER="zabbix" \
-e MYSQL_PASSWORD="kylin123." \
-e MYSQL_DATABASE="zabbix" \
-e ZBX_SERVER_HOST="zabbix-server" \
-e PHP_TZ="Asia/Shanghai" \
-p 8080:8080 \
-d zabbix/zabbix-web-nginx-mysql
```

登录访问测试

```sh
浏览器访问ip:8000查看
默认登录
username:Admin
password:zabbix
```

这里说明下，mysql没做数据卷的映射，nginx也没做数据卷的映射，在实际生产环境下，最好做数据映射。防止数据丢失。

### 安装agent

zabbix agent部署较为简单，你可以使用docker，也可以使用Yum、二进制包等方式安装，此处演示基于docker的安装方式。

下载镜像

```sh
$ docker pull zabbix/zabbix-agent:alpine-6.2-latest
```

创建存储卷，用于存储agent配置文件。

```sh
$ docker volume create -d local  zabbix_agent
```

启动agent容器

```sh
$ docker run --name zabbix-agent -t \
      -v zabbix_agent:/etc/zabbix \
      -e ZBX_HOSTNAME="host-01" \
      -e ZBX_SERVER_HOST="192.168.214.112" \ 
      -e ZBX_SERVER_PORT=10051 \
      -p 10050:10050 \
      --restart=unless-stopped \
      --privileged \
      -d zabbix/zabbix-agent:alpine-6.2-latest
```

注释：如果是部署在zabbix Server主机上的监控agent，此时的ZBX_SERVER_HOST需改为zabbix server的容器IP，而不能用主机IP。

```sh
docker run --name zabbix-agent --link zabbix-server-mysql:zabbix-server -d zabbix/zabbix-agent:latest
```

最后需要在web端将，zabbix-agent添加到zabbix-server的host列表里面。

![img](./assets/896726-20170716094442503-2125884891.png)

## 脚本部署

服务端安装脚本

```sh
#!/bin/bash
# 关闭防火墙，关闭selinux
systemctl stop firewalld && setenforce 0

#配置yum源
rpm -ivh http://repo.zabbix.com/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-2.el7.noarch.rpm && yum repolist

if [ -e /etc/yum.repos.d/zabbix.repo ];then
	echo "已存在"
	yum -y install zabbix-server-mysql zabbix-web-mysql zabbix-agent mariadb mariadb-server
	else
	echo "不存在"
	exit
fi

systemctl start mariadb
if [ $? -eq 0 ];then
	echo "service is started"
	else
	echo "service not started"
fi

#数据库的操作
mysql -e 'create database zabbix character set utf8 collate utf8_bin;'

#授权
mysql -e 'grant all privileges on zabbix.* to zabbix@localhost identified by "zabbix";'

#导入初始数据库
zcat `find / -name zabbix-server-mysql-*`/create.sql.gz | mysql -uzabbix -pzabbix zabbix

#修改配置文件
sed -i 's/# DBPassword=/DBPassword=zabbix/' /etc/zabbix/zabbix_server.conf

#编辑php文件
sed -i 's#;date.timezone =#date.timezone = Asia/Shanghai#' /etc/php.ini

#启动服务
systemctl start httpd zabbix-agent zabbix-server

#解决中文乱码，cp强制覆盖且不提示
yum -y install wqy-microhei-fonts
cp /usr/share/fonts/wqy-microhei/wqy-microhei.ttc /usr/share/fonts/dejavu/DejaVuSans.ttf

#输出信息
echo "浏览器访问 http://`hostname -I|awk '{print $1}'`/zabbix"
echo "登陆界面(区分大小写) 账号Admin密码zabbix"
```

 #zabbix客户端快速安装脚本

```sh
#!/bin/bash
# 安装zabbix源
rpm -Uvh https://repo.zabbix.com/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-2.el7.noarch.rpm
yum clean all && yum -y install zabbix-agent

# 修改Master为节点地址，ServerActive为被动接收监控
sed -i.brk "s/Server=127.0.0.1/Server=192.168.3.5/g" /etc/zabbix/zabbix_agentd.conf
sed -i "s/ServerActive=127.0.0.1/ServerActive=192.168.3.5/g" /etc/zabbix/zabbix_agentd.conf

# 修改该node机的主机名，在添加被监控时使用的
sed -i "s/Hostname=Zabbix server/Hostname=zabbix node1/g" /etc/zabbix/zabbix_agentd.conf 

# 开机自启服务
systemctl start  zabbix-agent.service && systemctl enable  zabbix-agent.service && service firewalld stop
echo 本机IP:`hostname -I|awk '{print $1}'`
```



# Prometheus普罗米修斯监控系统

Prometheus是开源系统监视和警报工具包

Prometheus的主要特点是：一个多维数据模型，其中包含通过度量标准名称和键/值对标识的时间序列数据

PromQL，一种灵活的查询语言，可以利用多维数据完成复杂的查询

不依赖分布式存储；单服务器节点是自治的

时间序列收集通过HTTP上的拉模型进行

通过中间网关支持推送时间序列

通过服务发现或静态配置发现目标

多种图形和仪表板支持模式

组件：Prometheus生态系统包含多个组件，其中许多是可选的：

Prometheus主服务器，它会刮取并存储时间序列数据

客户端库，用于检测应用程序代码

一个支持短期工作的推送网关

诸如HAProxy，StatsD，Graphite等服务的专用出口商

一个alertmanager处理警报

各种支持工具

大多数Prometheus组件都是用Go编写的，因此易于构建和部署为静态二进制文件

<img src="E:\Project\Textbook\linux云计算\assets\wps1-1682690463420-251.jpg" alt="img" style="zoom: 50%;" /> 

## 工作流程是：

Prometheus server 定期从配置好的 jobs 或者 exporters 中拉 metrics，或者接收来自Pushgateway 发过来的 metrics，或者从其他的 Prometheus server 中拉 metrics。

Prometheus server 在本地存储收集到的 metrics，并运行已定义好的 alert.rules，记录新的时间序列或者向 Alertmanager 推送警报。

Alertmanager 根据配置文件，对接收到的警报进行处理，发出告警。

在图形界面中，可视化采集数据。

传统的监控方式分为push和pull方式，prometheus支持默认的pull模式获取数据，这也是官方推荐的方式，但如果因为一些网络或防火墙等原因无法直接pull到数据的情况，就要借助Pushgateway让Prometheus转换为push方式获取数据。

总结：Prometheus 属于一站式监控告警平台，依赖少，功能齐全

Prometheus 支持对云或容器的监控，其他系统主要对主机监控

Prometheus 数据查询语句表现力更强大，内置更强大的统计函数

Prometheus 在数据存储扩展性以及持久性上没有 InfluxDB，OpenTSDB，Sensu 好

## prometheus服务端软件安装：

[prometheus下载地址](https://github.com/prometheus/prometheus/releases/download/v2.29.0-rc.1/prometheus-2.29.0-rc.1.linux-amd64.tar.gz)

```sh
tar -xzvf prometheus-2.29.0-rc.1.linux-amd64.tar.gz	#解压
cp promtool prometheus /usr/local/sbin/		#复制文件至启动文件夹
promtool check config prometheus.yml	#检查配置文件是否有问题
prometheus --config.file="prometheus.yml"	#启动服务指定配置文件，默认监听9090
-- storage.tsdb.path #指定数据文件存储的位置		--web.enable-lifecycle #支持热更新
```

docker容器安装启用：

```sh
docker run -d -p 9090:9090 -v /tmp/prometheus.yml:/prometheus/prometheus.yml prom/prometheus
```

global:

 scrape_interval:   15s #多久刷新一次目标。您可以为单个目标覆盖此目标。在这种情况下，全局设置是每15秒刷新一次

 evaluation_interval: 15s #多久评估一次规则。Prometheus使用规则来创建新的时间序列并生成警报

 

rule_files:	#指定加载的任何规则的位置

/# - "first.rules"

/#- "second.rules"

 

scrape_configs: #控制Prometheus监视哪些资源

 \- job_name: prometheus #job任务名称，可定义多个

  static_configs: #静态服务发现

   \- targets: ['localhost:9090'] #定义节点地址：收集信息端口号

 

  #honor_labels： #用于解决拉取数据标签有冲突，当设置为 true, 以拉取数据为准，否则以服务配置为准

  #params：#数据拉取访问时带的请求参数

  #scrape_timeout:  #拉取超时时间

  #metrics_path： #拉取节点的 metric 路径

  #scheme： #拉取数据访问协议

  #sample_limit： #存储的数据标签个数限制，如果超过限制，该数据将被忽略，不入存储；默认值为0，表示没有限制

  #relabel_configs： #拉取数据重置标签配置

  #metric_relabel_configs：metric #重置标签配置

## 服务发现：

  #dns_sd_configs: DNS 服务发现

  #file_sd_configs: 文件服务发现

  #consul_sd_configs: Consul 服务发现

  #serverset_sd_configs: Serverset 服务发现

  #nerve_sd_configs: Nerve 服务发现

  #marathon_sd_configs: Marathon 服务发现

  #kubernetes_sd_configs: Kubernetes 服务发现

  #gce_sd_configs: GCE 服务发现

  #ec2_sd_configs: EC2 服务发现

  #openstack_sd_configs: OpenStack 服务发现

  #azure_sd_configs: Azure 服务发现

  #triton_sd_configs: Triton 服务发现

## node_exporter监控节点：

Prometheus 监控模型: 主动抓取目标的指标接口(HTTP 协议)获取监控指标, 再存储到本地或远端的时序数据库,且对于指标接口有一套固定的格式要求

格式大致如下:

/# HELP http_requests_total The total number of HTTP requests.

/# TYPE http_requests_total counter

http_requests_total{method="post",code="200"} 1027

http_requests_total{method="post",code="400"}   3 

<img src="E:\Project\Textbook\linux云计算\assets\wps2-1682690463420-252.jpg" alt="img" style="zoom:67%;" /> 

[node_exporter下载地址](https://github.com/prometheus/node_exporter/releases/download/v1.2.2/node_exporter-1.2.2.linux-amd64.tar.gz)

cp /node_exporter/node_exporter /usr/local/sbin/ #命令拷贝至全局

node_exporter -h	#帮助命令，也可查看控制器打开状态

1、配置文本文件收集器：

mkdir -p  /var/lib/node_exporter/textfile_collector	#创建收集目录

echo 'metadata{role="docker_server",datacenter="NJ"}1' |tee metadata.prom

--collector.textfile.directory=""	#指定文本收集器目录

2、启用system收集器：	--collector.systemd（默认关闭）

--collector.systemd.unit-include=".+"

http://localhost:9100/metrics	#可以查看各项指标

## Pushgateway推送工具

Prometheus 采用 pull 模式，将不同数据汇总, 由 Prometheus 统一收集

弊端：将多个节点数据汇总到 pushgateway, 如果 pushgateway 挂了，受影响比多个 target 大

Prometheus 拉取状态 up 只对 pushgateway插件节点,

Pushgateway 可以持久化推送给它的所有监控数据，

因此，即使你的监控已经下线，prometheus 还会拉取到旧的监控数据，需要手动清理 pushgateway 不要的数据。 

下载地址：https://github.com/prometheus/pushgateway/releases/download/v1.4.1/pushgateway-1.4.1.linux-amd64.tar.gz

./pushgateway #启动，默认监听端口9091

## JDK部署安装

JDK（Java Development Kit）是面向对象程序设计语言的开发工具包，拥有这个工具包之后我们就可以使用Java语言进行程序设计和开发

mkdir /usr/lib/jdk	#建立jdk解压文件夹

 wget --no-check-certificate --no-cookies --header "Cookie: oraclelicense=accept-securebackup-cookie" http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.rpm

#在线下载jdk8

rpm -ivh jdk-8u131-linux-x64.rpm #安装

tar -xzvf jdk-14.0.1_linux-x64_bin.tar.gz -C /usr/java/jdk1.8.0_131	#进行解压

cd /usr/java/jdk1.8.0_131	#此目录包含了所有和Java运行环境相关的东西

JDK需要这样几个环境变量：

JAVA_HOME ：Java的主目录，把压缩包包解压之后得到的jdk-14文件夹所在的位置（并且包含jdk-14自身）

JRE_HOME：JRE的主目录，JRE是运行Java应用程序的最基本软件环境，所以如果你只是希望Java的程序能够运行的的话你完全不需要安装JDK，尽管JDK里面带有JRE。

CLASSPATH：Java提供的标准或公共类库的位置

PATH：这是系统的环境变量，这个东西只是告知系统你的Java开发环境被安装在了什么位置，这个东西使你在任意目录下都可以直接执行Java的开发工具比如javac等，直接进入javac就可以执行而不需要再重新进入入/usr/lib/jvm/jdk-13/bin/javac

vim /etc/profile			#配置环境

```sh
export JAVA_HOME=/usr/lib/jdk/jdk-14.0.1
export JRE_HOME=/${JAVA_HOME}
export CLASSPATH=.:${JAVA_HOME}/libss:${JRE_HOME}/lib
export PATH=${JAVA_HOME}/bin:$PATH
```

```
[root@localhost jdk-14.0.1]# java -version	#查看java版本号
[root@localhost jdk-14.0.1]# javac
[user@localhost ~/jsrc]$ vim Hello.java		#Java程序测试

public class Hello {// Hello.java
  public static void main(String args[]){
	System.out.println("Hello");
  }
}
```

openjdk：是开源社区开发的开源实现，yum list | grep openjdk查看jdk版本号

`yum install java-1.8.0 -y` #进行安装





# ELK日志分析系统

官方文档：https://www.elastic.co/guide/index.html

ELK 是一个常用的日志管理和分析平台，由 Elasticsearch、Logstash 和 Kibana 三个开源工具组成。ELK 平台通过集成这三个组件，提供了强大的日志收集、存储、搜索和可视化功能，使用户能够更好地管理和分析大量的日志数据。

以下是 ELK 中各个组件的功能和作用：

1. Elasticsearch：Elasticsearch 是一个分布式的实时搜索和分析引擎。它以文档为基本单位进行索引和存储，支持快速的全文搜索、复杂的查询和聚合操作。Elasticsearch 提供了强大的分布式架构，可以处理大规模的数据，并具有高可用性和可扩展性。
2. Logstash：Logstash 是一个日志收集和处理工具，可以从各种来源（如文件、网络、数据库）收集日志数据，并经过过滤、转换和解析后发送到 Elasticsearch 进行存储和索引。Logstash 支持丰富的插件机制，可以与各种数据源和目标进行集成。
3. Kibana：Kibana 是一个用于数据可视化的工具，它可以与 Elasticsearch 集成，通过直观的图表、仪表盘和搜索界面来展示和分析存储在 Elasticsearch 中的数据。Kibana 提供了灵活的查询和过滤功能，可以帮助用户快速定位和分析关键信息。

ELK 平台的工作流程通常如下：

1. Logstash 配置：在 Logstash 中配置数据源和目标，定义数据收集、过滤和转换规则。
2. 日志收集：Logstash 从配置好的数据源中收集日志数据，并按照配置的规则进行处理。
3. 数据存储：处理后的日志数据通过 Logstash 被发送到 Elasticsearch 进行存储和索引。
4. 数据可视化：使用 Kibana 连接到 Elasticsearch，通过创建仪表盘、图表和搜索等方式对数据进行可视化和分析。

ELK 平台的优势包括：

- 可扩展性：Elasticsearch 的分布式架构和可扩展性使其适合处理大规模的数据。
- 实时性：ELK 平台能够实时地处理和可视化日志数据，帮助用户及时发现问题和异常。
- 强大的搜索和查询功能：Elasticsearch 提供了强大的全文搜索和复杂的查询语言，使用户可以高效地查找和分析日志数据。
- 可视化和交互性：Kibana 提供直观的界面和丰富的可视化工具，使用户能够以交互方式探索和分析数据。

总结来说，ELK 是一个功能强大的日志管理和分析平台，适用于各种规模和类型的应用，可以帮助用户更好地收集、存储、搜索和可视化日志数据。

# Elasticsearch弹性搜索

它是一个开源分布式搜索引擎，提供收集、分析、存储数据三大功能。为了保证搜索服务的高可用性，需要一个集群

## 介绍

Elasticsearch（ES）是一个基于Lucene构建的开源、分布式、RESTful接口的全文搜索引擎。Elasticsearch还是一个分布式文档数据库，其中每个字段均可被索引，而且每个字段的数据均可被搜索，ES能够横向扩展至数以百计的服务器存储以及处理PB级的数据。可以在极短的时间内存储、搜索和分析大量的数据。通常作为具有复杂搜索场景情况下的核心发动机。

## Elasticsearch能做什么

1. 当你经营一家网上商店，你可以让你的客户搜索你卖的商品。在这种情况下，你可以使用ElasticSearch来存储你的整个产品目录和库存信息，为客户提供精准搜索，可以为客户推荐相关商品。
2. 当你想收集日志或者交易数据的时候，需要分析和挖掘这些数据，寻找趋势，进行统计，总结，或发现异常。在这种情况下，你可以使用Logstash或者其他工具来进行收集数据，当这引起数据存储到ElasticsSearch中。你可以搜索和汇总这些数据，找到任何你感兴趣的信息。
3. 对于程序员来说，比较有名的案例是GitHub，GitHub的搜索是基于ElasticSearch构建的，在github.com/search页面，你可以搜索项目、用户、issue、pull request，还有代码。共有40~50个索引库，分别用于索引网站需要跟踪的各种数据。虽然只索引项目的主分支（master），但这个数据量依然巨大，包括20亿个索引文档，30TB的索引文件。

## Elasticsearch基本概念

Near Realtime(NRT) 几乎实时

Elasticsearch是一个几乎实时的搜索平台。意思是，从索引一个文档到这个文档可被搜索只需要一点点的延迟，这个时间一般为毫秒级。

**Cluster 集群**

群集是一个或多个节点（服务器）的集合， 这些节点共同保存整个数据，并在所有节点上提供联合索引和搜索功能。一个集群由一个唯一集群ID确定，并指定一个集群名（默认为“elasticsearch”）。该集群名非常重要，因为节点可以通过这个集群名加入群集，一个节点只能是群集的一部分。

确保在不同的环境中不要使用相同的群集名称，否则可能会导致连接错误的群集节点。例如，你可以使用logging-dev、logging-stage、logging-prod分别为开发、阶段产品、生产集群做记录。

**Node节点**

节点是单个服务器实例，它是群集的一部分，可以存储数据，并参与群集的索引和搜索功能。就像一个集群，节点的名称默认为一个随机的通用唯一标识符（UUID），确定在启动时分配给该节点。如果不希望默认，可以定义任何节点名。这个名字对管理很重要，目的是要确定你的网络服务器对应于你的ElasticSearch群集节点。

我们可以通过群集名配置节点以连接特定的群集。默认情况下，每个节点设置加入名为“elasticSearch”的集群。这意味着如果你启动多个节点在网络上，假设他们能发现彼此都会自动形成和加入一个名为“elasticsearch”的集群。

在单个群集中，你可以拥有尽可能多的节点。此外，如果“elasticsearch”在同一个网络中，没有其他节点正在运行，从单个节点的默认情况下会形成一个新的单节点名为”elasticsearch”的集群。

**Index索引**

索引是具有相似特性的文档集合。例如，可以为客户数据提供索引，为产品目录建立另一个索引，以及为订单数据建立另一个索引。索引由名称（必须全部为小写）标识，该名称用于在对其中的文档执行索引、搜索、更新和删除操作时引用索引。在单个群集中，你可以定义尽可能多的索引。

**Type类型**

在索引中，可以定义一个或多个类型。类型是索引的逻辑类别/分区，其语义完全取决于你。一般来说，类型定义为具有公共字段集的文档。例如，假设你运行一个博客平台，并将所有数据存储在一个索引中。在这个索引中，你可以为用户数据定义一种类型，为博客数据定义另一种类型，以及为注释数据定义另一类型。

**Document文档**

文档是可以被索引的信息的基本单位。例如，你可以为单个客户提供一个文档，单个产品提供另一个文档，以及单个订单提供另一个文档。本文件的表示形式为JSON（JavaScript Object Notation）格式，这是一种非常普遍的互联网数据交换格式。

在索引/类型中，你可以存储尽可能多的文档。请注意，尽管文档物理驻留在索引中，文档实际上必须索引或分配到索引中的类型。

**Shards & Replicas分片与副本**

索引可以存储大量的数据，这些数据可能超过单个节点的硬件限制。例如，十亿个文件占用磁盘空间1TB的单指标可能不适合对单个节点的磁盘或可能太慢服务仅从单个节点的搜索请求。

为了解决这一问题，Elasticsearch提供细分你的指标分成多个块称为分片的能力。当你创建一个索引，你可以简单地定义你想要的分片数量。每个分片本身是一个全功能的、独立的“指数”，可以托管在集群中的任何节点。

**Shards分片的重要性主要体现在以下两个特征：**

1. 分片允许你水平拆分或缩放内容的大小
2. 分片允许你分配和并行操作的碎片（可能在多个节点上）从而提高性能/吞吐量 这个机制中的碎片是分布式的以及其文件汇总到搜索请求是完全由ElasticSearch管理，对用户来说是透明的。

在同一个集群网络或云环境上，故障是任何时候都会出现的，拥有一个故障转移机制以防分片和节点因为某些原因离线或消失是非常有用的，并且被强烈推荐。为此，Elasticsearch允许你创建一个或多个拷贝，你的索引分片进入所谓的副本或称作复制品的分片，简称Replicas。

Replicas的重要性主要体现在以下两个特征：

1. 副本为分片或节点失败提供了高可用性。为此，需要注意的是，一个副本的分片不会分配在同一个节点作为原始的或主分片，副本是从主分片那里复制过来的。
2. 副本允许用户扩展你的搜索量或吞吐量，因为搜索可以在所有副本上并行执行。

ES基本概念与关系型数据库的比较

| **ES概念**                                     | **关系型数据库**   |
| ---------------------------------------------- | ------------------ |
| Index（索引）支持全文检索                      | Database（数据库） |
| Type（类型）                                   | Table（表）        |
| Document（文档），不同文档可以有不同的字段集合 | Row（数据行）      |
| Field（字段）                                  | Column（数据列）   |
| Mapping（映射）                                | Schema（模式）     |

 

rpm --import http://packages.elasticsearch.org/GPG-KEY-elasticsearch

cat > /etc/yum.repos.d/elasticsearch.repo <<EOF

[elasticsearch] name=Elasticsearch repository for 8.x packages baseurl=https://artifacts.elastic.co/packages/8.x/yum gpgcheck=1 gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch enabled=0 autorefresh=1 type=rpm-md

EOF

yum install --enablerepo=elasticsearch elasticsearch //安装

 

 

 

二进制安装

https://www.elastic.co/cn/downloads/elasticsearch //elasticsearch下载地址

 

**报错解决方法**：

报错1、elasticsearch不能以root权限来运行，会出现这种错误：Exception in thread "main" java.lang.RuntimeException: don't run elasticsearch as root。

因为安全问题elasticsearch 不让用root用户直接运行，所以要创建新用户解决办法：

第一步：liunx创建新用户 adduser XXX 然后给创建的用户加密码 passwd XXX 输入两次密码。 

第二步：切换刚才创建的用户 su XXX 然后执行elasticsearch 会显示Permission denied 权限不足。

第三步：root给esuser赋权限， chown -R esuser elasticsearch-8.1.2 kibana-8.1.2安装目录。

第四步：切换su esuser用户， bin/elasticsearch -d  //以守护进程运行

 

报错2、elasticsearch8.0.1之后无法访问9200:Empty reply from server

在文件conf/elasticsearch.yml将 xpack.security.enable: true 改为 false

 

更多报错查询网址：

https://www.linuxprobe.com/elasticsearch-install-tutorial.html

 

 

使用

curl 'http://localhost:9200/?pretty' 查询服务是否启动

 

查看健康状态

curl -X GET 127.0.0.1:9200/_cat/health?v

 

查询当前es集群中所有的indices

curl -X GET 127.0.0.1:9200/_cat/indices?v

 

创建索引

curl -X PUT 127.0.0.1:9200/www

 

删除索引

curl -X DELETE 127.0.0.1:9200/www

 

插入记录

192.168.1.3:9200/student/_doc/  //以_doc为类型

 

 

 

# kibana安装

需先安装ES

https://www.elastic.co/cn/downloads/kibana 下载kibana地址

rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch #下载并安装公共签名密钥

cat > /etc/yum.repos.d/kibana.repo <<EOF

[kibana-8.x] name=Kibana repository for 8.x packages baseurl=https://artifacts.elastic.co/packages/8.x/yum gpgcheck=1 gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch enabled=1 autorefresh=1 type=rpm-md

EOF

yum install kibana -y //安装

service kibana start && systemctl enable kibana

 

 

二进制安装

vi config/kibana.yml  //配置文件

 

server.port: 5601  //开放端口

server.host: "192.168.1.3"  //映射地址

server.publicBaseUrl: "http://172.31.240.57:5601"  # 这里地址改为你访问kibana的地址，不能以 / 结尾

i18n.locale: "zh-CN"  //支持中文

 

bin/kibana --allow-root  &//后台运行启动，以root用户运行

 

 

 

 

 

 

# kafka分布式消息队列

Kafka是一个分布式数据流平台，可以运行在单台服务器上，也可以在多台服务器上部署形成集群。它提供了发布和订阅功能，使用者可以发送数据到Kafka中，也可以从Kafka中读取数据(以便进行后续的处理)。

Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的网站中的所有动作流数据，具有高性能、持久化、多副本备份、横向扩展等特点。

![img](E:\Project\Textbook\linux云计算\assets\wps23.png) 

 

### 一、Kafka集群的架构

Producer: 即生产者，消息的产生者，是消息的入口。

kafka cluster: kafka集群，-台或多台服务器组成

1、Broker: 指部署了Kafka实例的服务器节点（有唯一的标识）。每个服务器.上有一个或多个kafka的实例，我们姑且认为每个broker对应一台服务器。每个kafka集群内的broker都有-个不重复的编号，如图中的broker-0、broker-1等....

2、Topic: 消息的主题，可以理解为消息的分类，kafka的数据就保存在topic。在每个broker.上都可以创建多个topic。实际应用中通常是-个业务线建-个topic。

3、Partition: Topic的分区，每个topic可以有 多个分区，分区的作用是做负载，提高kafka的吞吐量。同一个topic在不同的分区的数据是不重复的，partition的表现形式就是一个-个的文件夹!

4、Replication:每- -个分区都有多个副本，副本的作用是做备胎。当主分区(Leader) 故障的时候会选择一个备胎(Follower). 上位， 成为Leader。在kafka中默认副本的最大数量是10个，且副本的数量不能大于Broker的数量，follower和leader绝对 是在不同的机器，同- -机器对同一个分区也只可能存放一个副本(包括自己)。

5、Consumer:消费者，即消息的消费方，是消息的出口。

Consumer Group:我们可以将多个消费组组成一个消费者组，在kafka的设计中同一个分区的数据只能被消费者组中的某一个消费者消费。同一个消费者组的消费者可以消费同-个topic的不同分区的数据，这也是为了提高kafka的吞吐量!

 

Leader:分区的主节点

Follower:分区的从节点

 

 

### 二、生产者往kafka发送数据的流程（6步）

![img](E:\Project\Textbook\linux云计算\assets\wps24.png) 

1.生产者从Kafka集群获取分区leader信息

2.生产者将消息发送给leader

3. leader将消息写入本地磁盘
4. follower从leader拉取消息数据
5. follower将消息写入本地磁盘后向leader发送ACK
6. leader收到所有的follower的ACK之后向生产者发送ACK

 

 

### 三、kafka选择分区的模式（3种）

1、指定往那个分区写

2、指定key，kafka根据key做hash然后决定写哪个分区

3、轮询方式

 

### 四、生产者往kafka发送数据的模式（3种）

`0`:把数据发给leader就成功，效率最高、安全性最低。

`1`:把数据发送给leader,等待leader回ACK

`a11` :把数据发给leader,确保follower从leader拉取数据回复ack给leader, leader再回复ACK;安全性最高

 

###最后要注意的是，如果往不存在的topic写数据，kafka会 自动创建topic, partition和replication的数量

默认配置都是1。

 

 

### 五、分区存储文件的原理

Topic和数据日志

topic是同一类别的消息记录(record) 的集合。在Kafka中，一个主题通常有多个订阅者。对于每个主题，Kafka集群维护 了一个分区数据日志文件结构如下:

![img](E:\Project\Textbook\linux云计算\assets\wps25.png) 

 

每个partition都是一个有序并 且不可变的消息记录集合。当新的数据写入时，就被追加到partition的末尾。在每个partition中，每条消息都会被分配- -个顺序的唯一标识， 这个标识被称为offset，即偏移量。注意，Kafka只保证在同一个partition内部消息是有序的，在不同partition之间， 并不能保证消息有序。

 

Kafka可以配置一个保留期限，用来标识日志会在Kafka集群内保留多长时间。Kafka集群会保留在保留期限内所有被发布的消息，不管这些消息是否被消费过。比如保留期限设置为两天，那么数据被发布到Kafka集群的两天以内，所有的这些数据都可以被消费。当超过两天，这些数据将会被清空，以便为后续的数据腾出空间。由于Kafka会将数据进行持久化存储(即写入到硬盘上)，所以保留的数据大小可以设置为一个比较大的值。

 

**Partition****结构**

Partition在服务器上的表现形式就是一个F 个的文件夹， 每个partition的文件夹 下面会有多组segment文件，每组segment文件又包含. index文件、.1og文件、 . timeindex文件三个文件，其中.1og文件就是实际存储message的地方，而. index和. time index文件为索引文件，用于检索消息。

 

### 六、为什么kafka快?

虽然是写入物理磁盘，但是每条记录都是通过index索引能快速定位

 

### 七、消费者组消费数据的原理

**消费数据**

多个消费者实例可以组成一个消费者组，并用一个标签来标识这个消费者组。一个消费者组中的不同消费者实例可以运行在不同的进程甚至不同的服务器上。如果所有的消费者实例都在同一个消费者组中，那么消息记录会被很好的均衡的发送到每个消费者实例。

如果所有的消费者实例都在不同的消费者组，那么每一条消息记录会被广播到每一个消费者实例。

![img](E:\Project\Textbook\linux云计算\assets\wps26.png) 

 

每个消费者实例可以消费多个分区,但是每个分区最多只能被消费者组中的一个实例消费。

 

 

 



 

# zookeeper服务注册发现

ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby- 个开源的实

现，它是集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作。最

终，将简单易用的接口和性能高效、功能稳定的系统提供给用户。

 

 

 

 

# Cacti服务器监控

C/S模式，采集监控数据		B/S模式，管理监测平台

Cacti是一套基于PHP,MySQL,SNMP及RRDTool开发的网络流量监测图形分析工具。它通过snmpget来获取数据，使用 RRDtool绘画图形，而且你完全可以不需要了解RRDtool复杂的参数。它提供了非常强大的数据和用户管理功能，可以指定每一个用户能查看树状结构、host以及任何一张图，还可以与LDAP结合进行用户验证，同时也能自己增加模板，功能非常强大完善。Cacti 的发展是基于让 RRDTool 使用者更方便使用该软件，除了基本的 Snmp 流量跟系统资讯监控外，Cacti 也可外挂 Scripts 及加上 Templates 来作出各式各样的监控图。

cacti是用php语言实现的一个软件，它的主要功能是用snmp服务获取数据，然后用rrdtool储存和更新数据，当用户需要查看数据的时候用rrdtool生成图表呈现给用户。因此，snmp和rrdtool是cacti的关键。Snmp关系着数据的收集，rrdtool关系着数据存储和图表的生成。

Mysql配合PHP程序存储一些变量数据并对变量数据进行调用，如：主机名、主机ip、snmp团体名、端口号、模板信息等变量

snmp抓到数据不是存储在mysql中，而是存在rrdtool生成的rrd文件中（在cacti根目录的rra文件夹下）。rrdtool对数据的更新和存储就是对rrd文件的处理，rrd文件是大小固定的档案文件（Round Robin Archive），它能够存储的数据笔数在创建时就已经定义。关于RRDTool的知识请参阅RRDTool教学。

snmp(Simple Network Management Protocal, 简单网络管理协议)在架构体系的监控子系统中将扮演重要角色。大体上，其基本原理是，在每一个被监控的主机或节点上 (如交换机)都运行了一个 agent，用来收集这个节点的所有相关的信息，同时监听 snmp 的 port，也就是 UDP 161，并从这个端口接收来自监控主机的指令(查询和设置)。

如果安装 net-snmp，被监控主机需要安装 net-snmp(包含了 snmpd 这个 agent)，而监控端需要安装 net-snmp-utils，若接受被监控端通过trap-communicate发来的信息的话，则需要安装net-snmp，并启用trap服务。如果自行编译，需要 beecrypt(libbeecrypt)和 elf(libraryelf)的库。

RRDtool是指Round Robin Database 工具（环状数据库）。Round robin是一种处理定量数据、以及当前元素指针的技术。想象一个周边标有点的圆环－－这些点就是时间存储的位置。从圆心画一条到圆周的某个点的箭头－－这就是指针。就像我们在一个圆环上一样，没有起点和终点，你可以一直往下走下去。过来一段时间，所有可用的位置都会被用过，该循环过程会自动重用原来的位置。这样，数据集不会增大，并且不需要维护。RRDtool处理RRD数据库。它用向RRD数据库存储数据、从RRD数据库中提取数据。

工作原理：snmp关系着数据的收集，rrdtool关系数据存储和图表的生成，snmp抓取的数据不是存储在数据库中，而是存储在rrdtool生成的rrd文件中

yum install epel-release.noarch -y

yum -y install httpd mariadb* php php-mysql zlib freetype libjpeg fontconfig libxml2 gd php-gd rrdtool net-snmp net-snmp-utils

yum install cacti -y

systemctl start httpd snmpd mariadb

cat> /var/www/html/index.php <<EOF

<?php

phpinfo();

?>

EOF

 

# Nagios监控系统

Nagios是一款开源的电脑系统和网络监视工具，能有效监控Windows、Linux和Unix的主机状态，交换机路由器等网络设备，打印机等。在系统或服务状态异常发出邮件或短信报警第一时间通知网站运维人员，在状态恢复后发出正常的邮件或者短信通知。

主要功能：  

网络服务监控（SMTP，POP3，HTTP，NNTP，ICMP，SNMP，FTP，SSH）

主机资源监控（CPU load，disk usage，system logs），也包括Windows主机（使用NSCLient+plugin）

可以指定自己编写的Plugin通过网络收集数据来监控任何情况（温度，警告。。。）

可以通过配置Nagios远程执行插件，远程执行脚本

远程监控支持ssh或ssl加通道方式进行监控

简单的plugin设计允许用户很容易的开发自己需要的检查服务，支持多开发语言（shell script，c++，Perl，Ruby，python，PHP，c#等）

包含很多图形化数据plugins（Nagiosgraph，Nagiosgrapher，PNP4Nagios等）

可并行服务检查

能够定义网络主机的层次，允许逐级检查，就是从父主机开始向下检查

当服务或主机出现问题时发出通告，可以通过email，pager，sms或任意用户自定义的plugin进行通知

能够自定义事件处理机制重新激活出问题的服务或主机

自动日志循环

支持冗余监控

包括web界面可以查看当前网络状态，通知，问题历史，日志文件等。

Centos7安装步骤（RHEL不同）：

setenforce 0 #关闭selinux

yum install -y gcc glibc glibc-common wget unzip httpd php gd gd-devel perl postfix #安装依赖软件库

wget https://github.com/NagiosEnterprises/nagioscore/archive/nagios-4.4.5.tar.gz #下载软件包

tar -xzvf nagioscore.tar.gz #进行解压

./configure  --prefix=/usr/local/nagios  --with-command-group=nagios && make all #指定安装路径和指定组

make install-groups-users #创建nagios用户和组

usermod -a -G nagios apache #将apache用户添加到所述的nagios组

make install #安装二进制文件，CGI和HTML文件

make install-daemoninit #安装守护程序文件

systemctl enable httpd.service

make install-commandmode #安装并配置外部命令文件

make install-config #安装* SAMPLE *配置文件，因为Nagios需要一些配置文件才能启动

make install-webconf #安装Apache Web 服务器配置文件

firewall-cmd --zone=public --add-port=http --permanent #允许本地防火墙通过http

htpasswd -c /usr/local/nagios/etc/htpasswd.users nagiosadmin #创建一个Apache用户帐户才能登录Nagios

systemctl start httpd nagios #启动web服务和nagios服务

http://10.25.5.143/nagios #将您的Web浏览器指向Nagios Core 服务器的IP地址或FQDN

安装nagios-plugins插件，安装依赖包：

yum install -y gcc glibc glibc-common make gettext automake autoconf wget openssl-devel net-snmp net-snmp-utils epel-release 

yum install -y perl-Net-SNMP

下载源：wget --no-check-certificate -O nagios-plugins.tar.gz https://github.com/nagios-plugins/nagios-plugins/archive/release-2.2.1.tar.gz 

解压：tar -zxvf nagios -plugins.tar.gz

编译安装：cd /nagios-plugins-release-2.2.1/ 

./tools/setup 

./configure --prefix=/usr/local/nagios-plugins  --with-command-group=nagios

make && make install && systemctl restart nagios.service

 

https://github.com/NagiosEnterprises/nrpe/releases/download/nrpe-4.0.2/nrpe-4.0.2.tar.gz

