# kubectl工具

# # kubectl安装与配置

# [1. kubectl的安装](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/install-kubectl.md#1-kubectl的安装)

```
curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl && chmod +x kubectl && sudo mv kubectl /usr/local/bin/
```



安装指定版本的kubectl，例如：`v1.9.0`

```
curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.9.0/bin/linux/amd64/kubectl && chmod +x kubectl && sudo mv kubectl /usr/local/bin/
```



# [2. 配置k8s集群环境](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/install-kubectl.md#2-配置k8s集群环境)

## [2.1. 命令行方式](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/install-kubectl.md#21-命令行方式)

### [2.1.1 非安全方式](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/install-kubectl.md#211-非安全方式)

```
kubectl config set-cluster k8s --server=http://<url> 
kubectl config set-context <NAMESPACE> --cluster=k8s --namespace=<NAMESPACE> 

kubectl config use-context <NAMESPACE> 
```



### [2.1.2 安全方式](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/install-kubectl.md#212-安全方式)

```
kubectl config set-cluster k8s --server=https://<url> --insecure-skip-tls-verify=true
kubectl config set-credentials k8s-user --username=<username> --password=<password>

kubectl config set-context <NAMESPACE> --cluster=k8s --user=k8s-user --namespace=<NAMESPACE> 
kubectl config use-context <NAMESPACE>
```



### [2.1.3 查询当前配置环境](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/install-kubectl.md#213-查询当前配置环境)

```
[root@test ]# kubectl cluster-info
Kubernetes master is running at http://192.168.10.3:8081
```



## [2.2. 添加配置文件的方式](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/install-kubectl.md#22-添加配置文件的方式)

当没有指定` --kubeconfig`参数和`$KUBECONFIG`的环境变量的时候，会默认读取`${HOME}/.kube/config`。

因此创建`${HOME}/.kube/config`文件，并在``${HOME}/.kube/ssl`目录下创建ca.pem、cert.pem、key.pem文件。

内容如下：

```
apiVersion: v1
kind: Config
clusters:
- name: local
  cluster:
    certificate-authority: ./ssl/ca.pem
    server: https://192.168.10.3:6443
users:
- name: kubelet
  user:
    client-certificate: ./ssl/cert.pem
    client-key: ./ssl/key.pem
contexts:
- context:
    cluster: local
    user: kubelet
  name: kubelet-cluster.local
current-context: kubelet-cluster.local
```



# [3. kubectl config](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/install-kubectl.md#3-kubectl-config)

kubectl config命令说明

```
$ kubectl config --help
Modify kubeconfig files using subcommands like "kubectl config set current-context my-context"

The loading order follows these rules:

  1. If the --kubeconfig flag is set, then only that file is loaded.  The flag may only be set once and no merging takes
place.
  2. If $KUBECONFIG environment variable is set, then it is used a list of paths (normal path delimitting rules for your
system).  These paths are merged.  When a value is modified, it is modified in the file that defines the stanza.  When a
value is created, it is created in the first file that exists.  If no files in the chain exist, then it creates the last
file in the list.
  3. Otherwise, ${HOME}/.kube/config is used and no merging takes place.

Available Commands:
  current-context Displays the current-context
  delete-cluster  Delete the specified cluster from the kubeconfig
  delete-context  Delete the specified context from the kubeconfig
  get-clusters    Display clusters defined in the kubeconfig
  get-contexts    Describe one or many contexts
  rename-context  Renames a context from the kubeconfig file.
  set             Sets an individual value in a kubeconfig file
  set-cluster     Sets a cluster entry in kubeconfig
  set-context     Sets a context entry in kubeconfig
  set-credentials Sets a user entry in kubeconfig
  unset           Unsets an individual value in a kubeconfig file
  use-context     Sets the current-context in a kubeconfig file
  view            Display merged kubeconfig settings or a specified kubeconfig file

Usage:
  kubectl config SUBCOMMAND [options]

Use "kubectl <command> --help" for more information about a given command.
Use "kubectl options" for a list of global command-line options (applies to all commands).
```



# [4. shell自动补齐](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/install-kubectl.md#4-shell自动补齐)

```
source <(kubectl completion bash)
echo "source <(kubectl completion bash)" >> ~/.bashrc
```



如果出现以下报错

```
# kubectl自动补齐失败
kubectl _get_comp_words_by_ref : command not found
```



解决方法：

```
yum install bash-completion -y

source /etc/profile.d/bash_completion.sh 
```



# kubectl命令说明

# [1. kubectl命令介绍](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-commands.md#1-kubectl命令介绍)

kubectl的命令语法

```
kubectl [command] [TYPE] [NAME] [flags]
```



其中command，TYPE，NAME，和flags分别是：

- `command`: 指定要在一个或多个资源进行操作，例如`create`，`get`，`describe`，`delete`。

- `TYPE`：指定[资源类型](https://kubernetes.io/cn/docs/user-guide/kubectl-overview/#资源类型)。资源类型区分大小写，您可以指定单数，复数或缩写形式。例如，以下命令产生相同的输出：

  ```
  kubectl get pod pod1  
  kubectl get pods pod1 
  kubectl get po pod1
  ```

  

- `NAME`：指定资源的名称。名称区分大小写。如果省略名称，则会显示所有资源的详细信息,比如`$ kubectl get pods`。

  按类型和名称指定多种资源：

  ```
  * 要分组资源，如果它们都是相同的类型：`TYPE1 name1 name2 name<#>`.<br/>
  例: `$ kubectl get pod example-pod1 example-pod2`
  
  * 要分别指定多种资源类型:  `TYPE1/name1 TYPE1/name2 TYPE2/name3 TYPE<#>/name<#>`.<br/>
  例: `$ kubectl get pod/example-pod1 replicationcontroller/example-rc1`
  ```

  

- `flags`：指定可选标志。例如，您可以使用`-s`或`--serverflags`来指定Kubernetes API服务器的地址和端口。

**更多命令介绍：**

```
[root@node5 ~]# kubectl
kubectl controls the Kubernetes cluster manager.

Find more information at https://github.com/kubernetes/kubernetes.

Basic Commands (Beginner):
  create         Create a resource from a file or from stdin.
  expose         Take a replication controller, service, deployment or pod and expose it as a new Kubernetes Service
  run            Run a particular image on the cluster
  set            Set specific features on objects
  run-container  Run a particular image on the cluster. This command is deprecated, use "run" instead

Basic Commands (Intermediate):
  get            Display one or many resources
  explain        Documentation of resources
  edit           Edit a resource on the server
  delete         Delete resources by filenames, stdin, resources and names, or by resources and label selector

Deploy Commands:
  rollout        Manage the rollout of a resource
  rolling-update Perform a rolling update of the given ReplicationController
  scale          Set a new size for a Deployment, ReplicaSet, Replication Controller, or Job
  autoscale      Auto-scale a Deployment, ReplicaSet, or ReplicationController

Cluster Management Commands:
  certificate    Modify certificate resources.
  cluster-info   Display cluster info
  top            Display Resource (CPU/Memory/Storage) usage.
  cordon         Mark node as unschedulable
  uncordon       Mark node as schedulable
  drain          Drain node in preparation for maintenance
  taint          Update the taints on one or more nodes

Troubleshooting and Debugging Commands:
  describe       Show details of a specific resource or group of resources
  logs           Print the logs for a container in a pod
  attach         Attach to a running container
  exec           Execute a command in a container
  port-forward   Forward one or more local ports to a pod
  proxy          Run a proxy to the Kubernetes API server
  cp             Copy files and directories to and from containers.
  auth           Inspect authorization

Advanced Commands:
  apply          Apply a configuration to a resource by filename or stdin
  patch          Update field(s) of a resource using strategic merge patch
  replace        Replace a resource by filename or stdin
  convert        Convert config files between different API versions

Settings Commands:
  label          Update the labels on a resource
  annotate       Update the annotations on a resource
  completion     Output shell completion code for the specified shell (bash or zsh)

Other Commands:
  api-versions   Print the supported API versions on the server, in the form of "group/version"
  config         Modify kubeconfig files
  help           Help about any command
  plugin         Runs a command-line plugin
  version        Print the client and server version information

Use "kubectl <command> --help" for more information about a given command.
Use "kubectl options" for a list of global command-line options (applies to all commands).
```



# [2. 操作的常用资源对象](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-commands.md#2-操作的常用资源对象)

1. Node
2. Podes
3. Replication Controllers
4. Services
5. Namespace
6. Deployment
7. StatefulSet

**具体对象类型及缩写：**

```
  * all
  * certificatesigningrequests (aka 'csr')
  * clusterrolebindings
  * clusterroles
  * componentstatuses (aka 'cs')
  * configmaps (aka 'cm')
  * controllerrevisions
  * cronjobs
  * customresourcedefinition (aka 'crd')
  * daemonsets (aka 'ds')
  * deployments (aka 'deploy')
  * endpoints (aka 'ep')
  * events (aka 'ev')
  * horizontalpodautoscalers (aka 'hpa')
  * ingresses (aka 'ing')
  * jobs
  * limitranges (aka 'limits')
  * namespaces (aka 'ns')
  * networkpolicies (aka 'netpol')
  * nodes (aka 'no')
  * persistentvolumeclaims (aka 'pvc')
  * persistentvolumes (aka 'pv')
  * poddisruptionbudgets (aka 'pdb')
  * podpreset
  * pods (aka 'po')
  * podsecuritypolicies (aka 'psp')
  * podtemplates
  * replicasets (aka 'rs')
  * replicationcontrollers (aka 'rc')
  * resourcequotas (aka 'quota')
  * rolebindings
  * roles
  * secrets
  * serviceaccounts (aka 'sa')
  * services (aka 'svc')
  * statefulsets (aka 'sts')
  * storageclasses (aka 'sc')
```



# [3. kubectl命令分类[command\]](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-commands.md#3-kubectl命令分类command)

## [3.1 增](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-commands.md#31-增)

1）create:[Create a resource by filename or stdin]

2）run:[ Run a particular image on the cluster]

3）apply:[Apply a configuration to a resource by filename or stdin]

4）proxy:[Run a proxy to the Kubernetes API server ]

## [3.2 删](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-commands.md#32-删)

1）delete:[Delete resources ]

## [3.3 改](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-commands.md#33-改)

1）scale:[Set a new size for a Replication Controller]

2）exec:[Execute a command in a container]

3）attach:[Attach to a running container]

4）patch:[Update field(s) of a resource by stdin]

5）edit:[Edit a resource on the server]

6） label:[Update the labels on a resource]

7）annotate:[Auto-scale a replication controller]

8）replace:[Replace a resource by filename or stdin]

9）config:[config modifies kubeconfig files]

## [3.4 查](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-commands.md#34-查)

1）get:[Display one or many resources]

2）describe:[Show details of a specific resource or group of resources]

3）log:[Print the logs for a container in a pod]

4）cluster-info:[Display cluster info]

5） version:[Print the client and server version information]

6）api-versions:[Print the supported API versions]

# [4. Pod相关命令](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-commands.md#4-pod相关命令)

## [4.1 查询Pod](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-commands.md#41-查询pod)

```
kubectl get pod -o wide --namespace=<NAMESPACE>
```



## [4.2 进入Pod](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-commands.md#42-进入pod)

```
kubectl exec -it <PodName> /bin/bash --namespace=<NAMESPACE>

# 进入Pod中指定容器
kubectl exec -it <PodName> -c <ContainerName> /bin/bash --namespace=<NAMESPACE>
```



## [4.3 删除Pod](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-commands.md#43-删除pod)

```
kubectl delete pod <PodName> --namespace=<NAMESPACE>

# 强制删除Pod，当Pod一直处于Terminating状态
kubectl delete pod <PodName> --namespace=<NAMESPACE> --force --grace-period=0

# 删除某个namespace下某个类型的所有对象
kubectl delete deploy --all --namespace=test
```



## [4.4 日志查看](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-commands.md#44-日志查看)

```
$ 查看运行容器日志 
kubectl logs <PodName> --namespace=<NAMESPACE>
$ 查看上一个挂掉的容器日志 
kubectl logs <PodName> -p --namespace=<NAMESPACE> 
```



# [5. 常用命令](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-commands.md#5-常用命令)

## [5.1. Node隔离与恢复](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-commands.md#51-node隔离与恢复)

说明：Node设置隔离之后，原先运行在该Node上的Pod不受影响，后续的Pod不会调度到被隔离的Node上。

**1. Node隔离**

```
# cordon命令
kubectl cordon <NodeName>
# 或者
kubectl patch node <NodeName> -p '{"spec":{"unschedulable":true}}'
```



**2. Node恢复**

```
# uncordon
kubectl uncordon <NodeName>
# 或者
kubectl patch node <NodeName> -p '{"spec":{"unschedulable":false}}'
```



## [5.2. kubectl label](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-commands.md#52-kubectl-label)

**1. 固定Pod到指定机器**

```
kubectl label node <NodeName> namespace/<NAMESPACE>=true
```



**2. 取消Pod固定机器**

```
kubectl label node <NodeName> namespace/<NAMESPACE>-
```



## [5.3. 升级镜像](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-commands.md#53-升级镜像)

```
# 升级镜像
kubectl set image deployment/nginx nginx=nginx:1.15.12 -n nginx
# 查看滚动升级情况
kubectl rollout status deployment/nginx  -n nginx
```



## [5.4. 调整资源值](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-commands.md#54-调整资源值)

```
# 调整指定容器的资源值
kubectl set resources sts nginx-0 -c=agent --limits=memory=512Mi -n nginx
```



## [5.5. 调整readiness probe](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-commands.md#55-调整readiness-probe)

```
# 批量查看readiness probe timeoutSeconds
kubectl get statefulset -o=jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.spec.template.spec.containers[0].readinessProbe.timeoutSeconds}{"\n"}{end}'

# 调整readiness probe timeoutSeconds参数
kubectl patch statefulset nginx-sts --type='json' -p='[{"op": "replace", "path": "/spec/template/spec/containers/0/readinessProbe/timeoutSeconds", "value":5}]' -n nginx
```



## [5.6. 调整tolerations属性](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-commands.md#56-调整tolerations属性)

```
kubectl patch statefulset nginx-sts --patch '{"spec": {"template": {"spec": {"tolerations": [{"effect": "NoSchedule","key": "dedicated","operator": "Equal","value": "nginx"}]}}}}' -n nginx
```



## [5.7. 查看所有节点的IP](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-commands.md#57-查看所有节点的ip)

```
kubectl get nodes -o=jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.status.addresses[0].address}{"\n"}{end}'
```



## [5.8. 查看当前k8s组件leader节点](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-commands.md#58-查看当前k8s组件leader节点)

当k8s集群高可用部署的时候，`kube-controller-manager`和`kube-scheduler`只能一个服务处于实际逻辑运行状态，通过参数`--leader-elect=true`来开启选举操作。以下提供查询leader节点的命令。

```
$ kubectl get endpoints kube-controller-manager --namespace=kube-system  -o yaml

apiVersion: v1
kind: Endpoints
metadata:
  annotations:
    control-plane.alpha.kubernetes.io/leader: '{"holderIdentity":"xxx.xxx.xxx.xxx_6537b938-7f5a-11e9-8487-00220d338975","leaseDurationSeconds":15,"acquireTime":"2019-05-26T02:03:18Z","renewTime":"2019-05-26T02:06:08Z","leaderTransitions":1}'
  creationTimestamp: "2019-05-26T01:52:39Z"
  name: kube-controller-manager
  namespace: kube-system
  resourceVersion: "1965"
  selfLink: /api/v1/namespaces/kube-system/endpoints/kube-controller-manager
  uid: f1755fc5-7f58-11e9-b4c4-00220d338975
```



以上表示`"holderIdentity":"xxx.xxx.xxx.xxx`为kube-controller-manager的leader节点。

同理，可以通过以下命令查看`kube-scheduler`的leader节点。

```
kubectl get endpoints kube-scheduler --namespace=kube-system  -o yaml
```



## [5.9. 修改副本数](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-commands.md#59-修改副本数)

```
kubectl scale deployment.v1.apps/nginx-deployment --replicas=10
```



## [5.10. 批量删除pod](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-commands.md#510-批量删除pod)

```
kubectl get po -n default |grep Evicted |awk '{print $1}' |xargs -I {} kubectl delete po  {} -n default
```



## [5.11. 各种查看命令](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-commands.md#511-各种查看命令)

```
# 不使用外部工具来输出解码后的 Secret
kubectl get secret my-secret -o go-template='{{range $k,$v := .data}}{{"### "}}{{$k}}{{"\n"}}{{$v|base64decode}}{{"\n\n"}}{{end}}'

# 列出事件（Events），按时间戳排序
kubectl get events --sort-by=.metadata.creationTimestamp
```



# [6. kubectl日志级别](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-commands.md#6-kubectl日志级别)

Kubectl 日志输出详细程度是通过 `-v` 或者 `--v` 来控制的，参数后跟一个数字表示日志的级别。 Kubernetes 通用的日志习惯和相关的日志级别在 [这里](https://github.com/kubernetes/community/blob/master/contributors/devel/sig-instrumentation/logging.md) 有相应的描述。

| 详细程度 | 描述                                                         |
| -------- | ------------------------------------------------------------ |
| `--v=0`  | 用于那些应该 *始终* 对运维人员可见的信息，因为这些信息一般很有用。 |
| `--v=1`  | 如果您不想要看到冗余信息，此值是一个合理的默认日志级别。     |
| `--v=2`  | 输出有关服务的稳定状态的信息以及重要的日志消息，这些信息可能与系统中的重大变化有关。这是建议大多数系统设置的默认日志级别。 |
| `--v=3`  | 包含有关系统状态变化的扩展信息。                             |
| `--v=4`  | 包含调试级别的冗余信息。                                     |
| `--v=5`  | 跟踪级别的详细程度。                                         |
| `--v=6`  | 显示所请求的资源。                                           |
| `--v=7`  | 显示 HTTP 请求头。                                           |
| `--v=8`  | 显示 HTTP 请求内容。                                         |
| `--v=9`  | 显示 HTTP 请求内容而且不截断内容。                           |

# kubectl命令别名

# [1. kubectl-aliases](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-alias.md#1-kubectl-aliases)

[kubectl-aliases](https://github.com/ahmetb/kubectl-aliases)开源工具是由[脚本](https://github.com/ahmetb/kubectl-aliases/blob/master/generate_aliases.py)通过拼接各种kubectl相关元素组成的[alias命令别名列表](https://github.com/ahmetb/kubectl-aliases/blob/master/.kubectl_aliases)，其中命令别名拼接元素如下：

| base      | [system?]        | [operation]                                        | [resource]                                                   | [flags]                                          |
| --------- | ---------------- | -------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------ |
| `k`ubectl | -n=kube-`sys`tem | `g`et `d`escribe `rm`:delete `lo`gs `ex`ec `a`pply | `po`ds `dep`loyment `sec`ret `ing`ress `no`de `svc` `ns` `cm` | `oyaml` `ojson` `owide` `all` `w`atch `f`ile `l` |

- ```
  k
  ```

  =kubectl

  - **sys**=`--namespace kube-system`

- commands:

  - **g**=`get`
  - **d**=`describe`
  - **rm**=`delete`
  - **a**:`apply -f`
  - **ex**: `exec -i -t`
  - **lo**: `logs -f`

- resources:

  - **po**=`pod`
  - **dep**=`deployment`
  - **ing**=`ingress`
  - **svc**=`service`
  - **cm**=`configmap`
  - **sec**=`secret`
  - **ns**=`namespace`
  - **no**=`node`

- flags:

  - output format: **oyaml**, **ojson**, **owide**
  - **all**: `--all` or `--all-namespaces` depending on the command
  - **sl**: `--show-labels`
  - **w**=`-w/--watch`

- value flags (should be at the end):

  - **f**=`-f/--filename`
  - **l**=`-l/--selector`

# [2. 示例](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-alias.md#2-示例)

```
# 示例1
kd → kubectl describe

# 示例2
kgdepallw → kubectl get deployment —all-namespaces —watch
```



**alias get示例：**

```
alias k='kubectl'
alias kg='kubectl get'
alias kgpo='kubectl get pods'
alias kgpoojson='kubectl get pods -o=json'
alias kgpon='kubectl get pods --namespace'
alias ksysgpooyamll='kubectl --namespace=kube-system get pods -o=yaml -l'
```



# [3. 安装](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-alias.md#3-安装)

```
# 将 .kubectl_aliases下载到 home 目录
cd ~ && wget https://raw.githubusercontent.com/ahmetb/kubectl-aliases/master/.kubectl_aliases

# 将以下内容添加到 .bashrc中，并执行 source .bashrc
[ -f ~/.kubectl_aliases ] && source ~/.kubectl_aliases
function kubectl() { command kubectl $@; }

# 如果需要提示别名的完整命令，则将以下内容添加到 .bashrc中，并执行 source .bashrc
[ -f ~/.kubectl_aliases ] && source ~/.kubectl_aliases
function kubectl() { echo "+ kubectl $@"; command kubectl $@; }
```



# kubectl进入node shell

## [1. 安装krew node-shell](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-node-shell.md#1-安装krew-node-shell)

### [1.1. 安装krew](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-node-shell.md#11-安装krew)

```
(
  set -x; cd "$(mktemp -d)" &&
  OS="$(uname | tr '[:upper:]' '[:lower:]')" &&
  ARCH="$(uname -m | sed -e 's/x86_64/amd64/' -e 's/\(arm\)\(64\)\?.*/\1\2/' -e 's/aarch64$/arm64/')" &&
  KREW="krew-${OS}_${ARCH}" &&
  curl -fsSLO "https://github.com/kubernetes-sigs/krew/releases/latest/download/${KREW}.tar.gz" &&
  tar zxvf "${KREW}.tar.gz" &&
  ./"${KREW}" install krew
)
```



在`~/.bashrc`或`~/.zshrc`添加以下命令

```
export PATH="${KREW_ROOT:-$HOME/.krew}/bin:$PATH"
```



### [1.2. 安装node-shell](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-node-shell.md#12-安装node-shell)

node-shell的代码参考：[kubectl-node-shell/kubectl-node_shell at master · kvaps/kubectl-node-shell · GitHub](https://github.com/kvaps/kubectl-node-shell/blob/master/kubectl-node_shell)

```
kubectl krew install node-shell
```



示例：

```
# kubectl krew install node-shell
Updated the local copy of plugin index.
Installing plugin: node-shell
Installed plugin: node-shell
\
 | Use this plugin:
 |     kubectl node-shell
 | Documentation:
 |     https://github.com/kvaps/kubectl-node-shell
 | Caveats:
 | \
 |  | You need to be allowed to start privileged pods in the cluster
 | /
/
WARNING: You installed plugin "node-shell" from the krew-index plugin repository.
   These plugins are not audited for security by the Krew maintainers.
   Run them at your own risk.
```



## [2. 进入节点的shell](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-node-shell.md#2-进入节点的shell)

### [2.1. 登录node](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-node-shell.md#21-登录node)

创建一个临时的特权容器，登录容器即登录node shell。

```
kubectl node-shell <node-name>
```



示例：

```
# kubectl node-shell node1
spawning "nsenter-9yqytp" on "node1"
If you don't see a command prompt, try pressing enter.
groups: cannot find name for group ID 11
To run a command as administrator (user "root"), use "sudo <command>".
See "man sudo_root" for details.

root@node1:/#
```



### [2.2. 退出node](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-node-shell.md#22-退出node)

退出容器，容器会被自动删除。

```
# exit
logout
pod default/nsenter-9yqytp terminated (Error)
pod "nsenter-9yqytp" deleted
```



## [3. 原理](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-node-shell.md#3-原理)

容器是弱隔离，共享节点的内核，通过cgroup和namespace来实现进程级别的隔离。那么通过在特权容器里执行`nsenter`的命令，则可以通过登录特权容器来实现登录node的shell环境。

创建一个特权容器，进入node shell的命令为：

```
nsenter --target 1 --mount --uts --ipc --net --pid -- bash -l
```



进入 node shell 的权限：

- `hostPID: true` 共享 host 的 pid
- `hostNetwork: true` 共享 host 的网络
- `privileged: true`: PSP 权限策略是 `privileged`, 即完全无限制。

### [3.1. Pod.yaml](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/kubectl-node-shell.md#31-podyaml)

```
apiVersion: v1
kind: Pod
metadata:
  labels:
    run: nsenter-9yqytp
  name: nsenter-9yqytp
  namespace: default
spec:
  containers:
  - command:
    - nsenter
    - --target
    - "1"
    - --mount
    - --uts
    - --ipc
    - --net
    - --pid
    - --
    - bash
    - -l
    image: docker.io/library/alpine
    imagePullPolicy: Always
    name: nsenter
    resources:
      limits:
        cpu: 100m
        memory: 256Mi
      requests:
        cpu: 100m
        memory: 256Mi
    securityContext:
      privileged: true
    stdin: true
    stdinOnce: true
    tty: true
    volumeMounts:
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-4ktlf
      readOnly: true
  enableServiceLinks: true
  hostNetwork: true
  hostPID: true
  nodeName: node1
  preemptionPolicy: PreemptLowerPriority
  priority: 0
  restartPolicy: Never
  schedulerName: default-scheduler
  securityContext: {}
  serviceAccount: default
  serviceAccountName: default
  tolerations:
  - key: CriticalAddonsOnly
    operator: Exists
  - effect: NoExecute
    operator: Exists
  volumes:
  - name: kube-api-access-4ktlf
    projected:
      defaultMode: 420
      sources:
      - serviceAccountToken:
          expirationSeconds: 3607
          path: token
      - configMap:
          items:
          - key: ca.crt
            path: ca.crt
          name: kube-root-ca.crt
      - downwardAPI:
          items:
          - fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
            path: namespace
```



创建完容器后，直接登录容器即可登录节点的shell

```
kubectl exec -it nsenter-9yqytp bash
```

# helm的使用

# [1. 安装helm](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/helm-usage.md#1-安装helm)

```
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
```



# [2. 基本概念](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/helm-usage.md#2-基本概念)

Helm是用来管理k8s集群上的软件包。

- `Chart`:代表helm软件包
- `Repository`：软件包的存放仓库
- `Release`:运行在k8s上的一个发布实例。

# [3. helm命令](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/helm-usage.md#3-helm命令)

```
Usage:
  helm [command]

Available Commands:
  completion  generate autocompletion scripts for the specified shell
  create      create a new chart with the given name
  dependency  manage a chart's dependencies
  env         helm client environment information
  get         download extended information of a named release
  help        Help about any command
  history     fetch release history
  install     install a chart
  lint        examine a chart for possible issues
  list        list releases
  package     package a chart directory into a chart archive
  plugin      install, list, or uninstall Helm plugins
  pull        download a chart from a repository and (optionally) unpack it in local directory
  push        push a chart to remote
  registry    login to or logout from a registry
  repo        add, list, remove, update, and index chart repositories
  rollback    roll back a release to a previous revision
  search      search for a keyword in charts
  show        show information of a chart
  status      display the status of the named release
  template    locally render templates
  test        run tests for a release
  uninstall   uninstall a release
  upgrade     upgrade a release
  verify      verify that a chart at the given path has been signed and is valid
  version     print the client version information
```



# [4. 常用命令](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/helm-usage.md#4-常用命令)

## [4.1. helm search](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/helm-usage.md#41-helm-search)

- helm search hub：从 [Artifact Hub](https://artifacthub.io/) 中查找并列出 helm charts。支持模糊匹配。

```
helm search hub wordpress
```



- helm search repo：基于指定仓库进行搜索。

```
helm repo add brigade https://brigadecore.github.io/charts
helm search repo brigade

# 列出所有版本
helm search repo apisix -l
```



## [4.2. helm install/uninstall](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/helm-usage.md#42-helm-installuninstall)

```
helm install <release_name> <chart_name>
# 示例
helm install happy-panda bitnami/wordpress -

# uninstall
helm uninstall RELEASE_NAME
```



安装自定义chart

```
helm install -f values.yaml bitnami/wordpress --generate-name

# 本地 chart 压缩包
helm install foo foo-0.1.1.tgz
# 解压后的 chart 目录
helm install foo path/to/foo
# 完整的 URL
helm install foo https://example.com/charts/foo-1.2.3.tgz
```



## [4.3. helm upgrade](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/helm-usage.md#43-helm-upgrade)

```
helm upgrade happy-panda bitnami/wordpress
```



## [4.4. helm rollback](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/helm-usage.md#44-helm-rollback)

```
helm rollback <RELEASE> [REVISION] [flags]
```



## [4.5. helm repo](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/helm-usage.md#45-helm-repo)

```
helm repo add dev https://example.com/dev-charts
helm repo list
helm repo remove
```



## [4.6. helm pull](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/helm-usage.md#46-helm-pull)

从仓库下载并（可选）在本地目录解压。

```
helm pull [chart URL | repo/chartname]


helm pull [chart URL | repo/chartname] --version 
```



# [5. 新建一个chart](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubectl/helm-usage.md#5-新建一个chart)

```
 helm create mychart
```



查看生成的文件目录：

```
mychart
|-- charts
|-- Chart.yaml
|-- templates
|   |-- deployment.yaml
|   |-- _helpers.tpl
|   |-- hpa.yaml
|   |-- ingress.yaml
|   |-- NOTES.txt
|   |-- serviceaccount.yaml
|   |-- service.yaml
|   `-- tests
|       `-- test-connection.yaml
`-- values.yaml
```

# kubernetes集群问题排查

# [1. 查看系统Event事件](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubernetes-troubleshooting.md#1-查看系统event事件)

```
kubectl describe pod <PodName> --namespace=<NAMESPACE> 
```



该命令可以显示Pod创建时的配置定义、状态等信息和最近的Event事件，事件信息可用于排错。例如当Pod状态为Pending，可通过查看Event事件确认原因，一般原因有几种：

- 没有可用的Node可调度
- 开启了资源配额管理并且当前Pod的目标节点上恰好没有可用的资源
- 正在下载镜像（镜像拉取耗时太久）或镜像下载失败。

kubectl describe还可以查看其它k8s对象：NODE,RC,Service,Namespace,Secrets。

## [1.1. Pod](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubernetes-troubleshooting.md#11-pod)

```
kubectl describe pod <PodName> --namespace=<NAMESPACE>
```



以下是容器的启动命令非阻塞式导致容器挂掉，被k8s频繁重启所产生的事件。

```
kubectl describe pod <PodName> --namespace=<NAMESPACE>  

Events:
  FirstSeen LastSeen    Count   From            SubobjectPath       Reason      Message
  ───────── ────────    ─────   ────            ─────────────       ──────      ───────
  7m        7m      1   {scheduler }                    Scheduled   Successfully assigned yangsc-1-0-0-index0 to 10.8.216.19
  7m        7m      1   {kubelet 10.8.216.19}   containers{infra}   Pulled      Container image "gcr.io/kube-system/pause:0.8.0" already present on machine
  7m        7m      1   {kubelet 10.8.216.19}   containers{infra}   Created     Created with docker id 84f133c324d0
  7m        7m      1   {kubelet 10.8.216.19}   containers{infra}   Started     Started with docker id 84f133c324d0
  7m        7m      1   {kubelet 10.8.216.19}   containers{yangsc0} Started     Started with docker id 3f9f82abb145
  7m        7m      1   {kubelet 10.8.216.19}   containers{yangsc0} Created     Created with docker id 3f9f82abb145
  7m        7m      1   {kubelet 10.8.216.19}   containers{yangsc0} Created     Created with docker id fb112e4002f4
  7m        7m      1   {kubelet 10.8.216.19}   containers{yangsc0} Started     Started with docker id fb112e4002f4
  6m        6m      1   {kubelet 10.8.216.19}   containers{yangsc0} Created     Created with docker id 613b119d4474
  6m        6m      1   {kubelet 10.8.216.19}   containers{yangsc0} Started     Started with docker id 613b119d4474
  6m        6m      1   {kubelet 10.8.216.19}   containers{yangsc0} Created     Created with docker id 25cb68d1fd3d
  6m        6m      1   {kubelet 10.8.216.19}   containers{yangsc0} Started     Started with docker id 25cb68d1fd3d
  5m        5m      1   {kubelet 10.8.216.19}   containers{yangsc0} Started     Started with docker id 7d9ee8610b28
  5m        5m      1   {kubelet 10.8.216.19}   containers{yangsc0} Created     Created with docker id 7d9ee8610b28
  3m        3m      1   {kubelet 10.8.216.19}   containers{yangsc0} Started     Started with docker id 88b9e8d582dd
  3m        3m      1   {kubelet 10.8.216.19}   containers{yangsc0} Created     Created with docker id 88b9e8d582dd
  7m        1m      7   {kubelet 10.8.216.19}   containers{yangsc0} Pulling     Pulling image "gcr.io/test/tcp-hello:1.0.0"
  1m        1m      1   {kubelet 10.8.216.19}   containers{yangsc0} Started     Started with docker id 089abff050e7
  1m        1m      1   {kubelet 10.8.216.19}   containers{yangsc0} Created     Created with docker id 089abff050e7
  7m        1m      7   {kubelet 10.8.216.19}   containers{yangsc0} Pulled      Successfully pulled image "gcr.io/test/tcp-hello:1.0.0"
  6m        7s      34  {kubelet 10.8.216.19}   containers{yangsc0} Backoff     Back-off restarting failed docker container
```



## [1.2. NODE](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubernetes-troubleshooting.md#12-node)

```
kubectl describe node 10.8.216.20
```



```
[root@FC-43745A-10 ~]# kubectl describe node 10.8.216.20  
Name:           10.8.216.20  
Labels:         kubernetes.io/hostname=10.8.216.20,namespace/bcs-cc=true,namespace/myview=true  
CreationTimestamp:  Mon, 17 Apr 2017 11:32:52 +0800  
Phase:            
Conditions:  
  Type      Status  LastHeartbeatTime           LastTransitionTime          Reason              Message  
  ────      ──────  ─────────────────           ──────────────────          ──────              ───────  
  Ready     True    Fri, 18 Aug 2017 09:38:33 +0800     Tue, 02 May 2017 17:40:58 +0800     KubeletReady            kubelet is posting ready status  
  OutOfDisk     False   Fri, 18 Aug 2017 09:38:33 +0800     Mon, 17 Apr 2017 11:31:27 +0800     KubeletHasSufficientDisk    kubelet has sufficient disk space available  
Addresses:  10.8.216.20,10.8.216.20  
Capacity:  
 cpu:       32  
 memory:    67323039744  
 pods:      40  
System Info:  
 Machine ID:            723bafc7f6764022972b3eae1ce6b198  
 System UUID:           4C4C4544-0042-4210-8044-C3C04F595631  
 Boot ID:           da01f2e3-987a-425a-9ca7-1caaec35d1e5  
 Kernel Version:        3.10.0-327.28.3.el7.x86_64  
 OS Image:          CentOS Linux 7 (Core)  
 Container Runtime Version: docker://1.13.1  
 Kubelet Version:       v1.1.1-xxx2-13.1+79c90c68bfb72f-dirty  
 Kube-Proxy Version:        v1.1.1-xxx2-13.1+79c90c68bfb72f-dirty  
ExternalID:         10.8.216.20  
Non-terminated Pods:        (6 in total)  
  Namespace         Name                    CPU Requests    CPU Limits  Memory Requests Memory Limits  
  ─────────         ────                    ────────────    ──────────  ─────────────── ─────────────  
  bcs-cc            bcs-cc-api-0-0-1364-index0      1 (3%)      1 (3%)      4294967296 (6%) 4294967296 (6%)  
  bcs-cc            bcs-cc-api-0-0-1444-index0      1 (3%)      1 (3%)      4294967296 (6%) 4294967296 (6%)  
  fw                fw-demo2-0-0-1519-index0        1 (3%)      1 (3%)      4294967296 (6%) 4294967296 (6%)  
  myview            myview-api-0-0-1362-index0      1 (3%)      1 (3%)      4294967296 (6%) 4294967296 (6%)  
  myview            myview-api-0-0-1442-index0      1 (3%)      1 (3%)      4294967296 (6%) 4294967296 (6%)  
  qa-ts-dna         ts-dna-console3-0-0-1434-index0     1 (3%)      1 (3%)      4294967296 (6%) 4294967296 (6%)  
Allocated resources:  
  (Total limits may be over 100%, i.e., overcommitted. More info: http://releases.k8s.io/HEAD/docs/user-guide/compute-resources.md)  
  CPU Requests  CPU Limits  Memory Requests     Memory Limits  
  ────────────  ──────────  ───────────────     ─────────────  
  6 (18%)   6 (18%)     25769803776 (38%)   25769803776 (38%)  
No events.  
```



## [1.3. RC](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubernetes-troubleshooting.md#13-rc)

```
kubectl describe rc mytest-1-0-0 --namespace=test
```



```
[root@FC-43745A-10 ~]# kubectl describe rc mytest-1-0-0 --namespace=test  
Name:       mytest-1-0-0  
Namespace:  test  
Image(s):   gcr.io/test/mywebcalculator:1.0.1  
Selector:   app=mytest,appVersion=1.0.0  
Labels:     app=mytest,appVersion=1.0.0,env=ts,zone=inner  
Replicas:   1 current / 1 desired  
Pods Status:    1 Running / 0 Waiting / 0 Succeeded / 0 Failed  
No volumes.  
Events:  
  FirstSeen LastSeen    Count   From                SubobjectPath   Reason          Message  
  ───────── ────────    ─────   ────                ─────────────   ──────          ───────  
  20h       19h     9   {replication-controller }           FailedCreate        Error creating: Pod "mytest-1-0-0-index0" is forbidden: limited to 10 pods  
  20h       17h     7   {replication-controller }           FailedCreate        Error creating: pods "mytest-1-0-0-index0" already exists  
  20h       17h     4   {replication-controller }           SuccessfulCreate    Created pod: mytest-1-0-0-index0  
```



## [1.4. NAMESPACE](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubernetes-troubleshooting.md#14-namespace)

```
kubectl describe namespace test
```



```
[root@FC-43745A-10 ~]# kubectl describe namespace test  
Name:   test  
Labels: <none>  
Status: Active  
  
Resource Quotas  
 Resource       Used        Hard  
 ---            ---     ---  
 cpu            5       20  
 memory         1342177280  53687091200  
 persistentvolumeclaims 0       10  
 pods           4       10  
 replicationcontrollers 8       20  
 resourcequotas     1       1  
 secrets        3       10  
 services       8       20  
  
No resource limits.  
```



## [1.5. Service](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubernetes-troubleshooting.md#15-service)

```
kubectl describe service xxx-containers-1-1-0 --namespace=test
```



```
[root@FC-43745A-10 ~]# kubectl describe service xxx-containers-1-1-0 --namespace=test  
Name:           xxx-containers-1-1-0  
Namespace:      test  
Labels:         app=xxx-containers,appVersion=1.1.0,env=ts,zone=inner  
Selector:       app=xxx-containers,appVersion=1.1.0  
Type:           ClusterIP  
IP:         10.254.46.42  
Port:           port-dna-tcp-35913  35913/TCP  
Endpoints:      10.0.92.17:35913  
Port:           port-l7-tcp-8080    8080/TCP  
Endpoints:      10.0.92.17:8080  
Session Affinity:   None  
No events.  
```



# [2. 查看容器日志](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubernetes-troubleshooting.md#2-查看容器日志)

1、查看指定pod的日志

```
kubectl logs <pod_name>

kubectl logs -f <pod_name> #类似tail -f的方式查看
```



2、查看上一个pod的日志

```
kubectl logs -p <pod_name>
```



3、查看指定pod中指定容器的日志

```
kubectl logs <pod_name> -c <container_name>
```



4、kubectl logs --help

```
[root@node5 ~]# kubectl logs --help  
Print the logs for a container in a pod. If the pod has only one container, the container name is optional.  
Usage:  
  kubectl logs [-f] [-p] POD [-c CONTAINER] [flags]  
Aliases:  
  logs, log  
   
Examples:  
# Return snapshot logs from pod nginx with only one container  
$ kubectl logs nginx  
# Return snapshot of previous terminated ruby container logs from pod web-1  
$ kubectl logs -p -c ruby web-1  
# Begin streaming the logs of the ruby container in pod web-1  
$ kubectl logs -f -c ruby web-1  
# Display only the most recent 20 lines of output in pod nginx  
$ kubectl logs --tail=20 nginx  
# Show all logs from pod nginx written in the last hour  
$ kubectl logs --since=1h nginx  
```



# [3. 查看k8s服务日志](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubernetes-troubleshooting.md#3-查看k8s服务日志)

## [3.1. journalctl](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubernetes-troubleshooting.md#31-journalctl)

在Linux系统上systemd系统来管理kubernetes服务，并且journal系统会接管服务程序的输出日志，可以通过**systemctl status 或journalctl -u -f**来查看kubernetes服务的日志。

其中kubernetes组件包括：

| k8s组件                 | 涉及日志内容                  | 备注 |
| ----------------------- | ----------------------------- | ---- |
| kube-apiserver          |                               |      |
| kube-controller-manager | Pod扩容相关或RC相关           |      |
| kube-scheduler          | Pod扩容相关或RC相关           |      |
| kubelet                 | Pod生命周期相关：创建、停止等 |      |
| etcd                    |                               |      |

## [3.2. 日志文件](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubernetes-troubleshooting.md#32-日志文件)

也可以通过指定日志存放目录来保存和查看日志

- --logtostderr=false：不输出到stderr
- --log-dir=/var/log/kubernetes:日志的存放目录
- --alsologtostderr=false:设置为true表示日志输出到文件也输出到stderr
- --v=0:glog的日志级别
- --vmodule=gfs*=2,test*=4：glog基于模块的详细日志级别

# [4. 常见问题](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubernetes-troubleshooting.md#4-常见问题)

## [4.1. Pod状态一直为Pending](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubernetes-troubleshooting.md#41-pod状态一直为pending)

```
kubectl describe <pod_name> --namespace=<NAMESPACE>
```



查看该POD的事件。

- 正在下载镜像但拉取不下来（镜像拉取耗时太久）[一般都是该原因]
- 没有可用的Node可调度
- 开启了资源配额管理并且当前Pod的目标节点上恰好没有可用的资源

解决方法：

1. 查看该POD所在宿主机与镜像仓库之间的网络是否有问题，可以手动拉取镜像
2. 删除POD实例，让POD调度到别的宿主机上

## [4.2. Pod创建后不断重启](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/kubernetes-troubleshooting.md#42-pod创建后不断重启)

kubectl get pods中Pod状态一会running，一会不是，且RESTARTS次数不断增加。

一般原因为容器启动命令不是阻塞式命令，导致容器运行后马上退出。

非阻塞式命令：

- 本身CMD指定的命令就是非阻塞式命令
- 将服务启动方式设置为后台运行

解决方法：

1、将命令改为阻塞式命令（前台运行），例如：**zkServer.sh start-foreground**

2、java运行程序的启动脚本将 nohup xxx &的nobup和&去掉，例如：

```
nohup JAVA_HOME/bin/java JAVA_OPTS -cp $CLASSPATH com.cnc.open.processor.Main &
```



改为：

```
JAVA_HOME/bin/java JAVA_OPTS -cp $CLASSPATH com.cnc.open.processor.Main
```

# 节点调度
# 安全迁移节点

# [1. 迁移Pod](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/node/safely-drain-node.md#1-迁移pod)

## [1.1. 设置节点是否可调度](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/node/safely-drain-node.md#11-设置节点是否可调度)

确定需要迁移和被迁移的节点，将不允许被迁移的节点设置为不可调度。

```
# 查看节点
kubectl get nodes

# 设置节点为不可调度
kubectl cordon <NodeName>

# 设置节点为可调度
kubectl uncordon <NodeName>
```



## [1.2. 执行kubectl drain命令](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/node/safely-drain-node.md#12-执行kubectl-drain命令)

```
kubectl drain <NodeName> --force --ignore-daemonsets
```



示例：

```
$ kubectl drain bjzw-prek8sredis-99-40 --force --ignore-daemonsets
node "bjzw-prek8sredis-99-40" already cordoned
WARNING: Deleting pods not managed by ReplicationController, ReplicaSet, Job, DaemonSet or StatefulSet: kube-proxy-bjzw-prek8sredis-99-40; Ignoring DaemonSet-managed pods: calicoopsmonitor-mfpqs, arachnia-agent-j56n8
pod "pre-test-pro2-r-0-redis-2-8-19-1" evicted
pod "pre-test-hwh1-r-8-redis-2-8-19-2" evicted
pod "pre-eos-hdfs-vector-eos-hdfs-redis-2-8-19-0" evicted
```



## [1.3. 特别说明](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/node/safely-drain-node.md#13-特别说明)

对于statefulset创建的Pod，kubectl drain的说明如下：

kubectl drain操作会将相应节点上的旧Pod删除，并在可调度节点上面起一个对应的Pod。当旧Pod没有被正常删除的情况下，新Pod不会起来。例如：旧Pod一直处于`Terminating`状态。

对应的解决方式是通过重启相应节点的kubelet，或者强制删除该Pod。

示例：

```
# 重启发生`Terminating`节点的kubelet
systemctl restart kubelet

# 强制删除`Terminating`状态的Pod
kubectl delete pod <PodName> --namespace=<Namespace> --force --grace-period=0
```



# [2. kubectl drain 流程图](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/node/safely-drain-node.md#2-kubectl-drain-流程图)

[![img](https://camo.githubusercontent.com/2597f3064d744dcfb619c5e93a2269877edb532d6d10d0b65e34c17ed6cc16d0/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f647178746e3069636b2f696d6167652f75706c6f61642f76313533373235393737392f61727469636c652f6b756265726e657465732f6f7065726174696f6e2f6b75626563746c2d647261696e2e737667)](https://camo.githubusercontent.com/2597f3064d744dcfb619c5e93a2269877edb532d6d10d0b65e34c17ed6cc16d0/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f647178746e3069636b2f696d6167652f75706c6f61642f76313533373235393737392f61727469636c652f6b756265726e657465732f6f7065726174696f6e2f6b75626563746c2d647261696e2e737667)

# [3. TroubleShooting](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/node/safely-drain-node.md#3-troubleshooting)

1、存在不是通过`ReplicationController`, `ReplicaSet`, `Job`, `DaemonSet` 或者` StatefulSet`创建的Pod（即静态pod，通过文件方式创建的），所以需要设置强制执行的参数`--force`。

```
$ kubectl drain bjzw-prek8sredis-99-40
node "bjzw-prek8sredis-99-40" already cordoned
error: unable to drain node "bjzw-prek8sredis-99-40", aborting command...

There are pending nodes to be drained:
 bjzw-prek8sredis-99-40
error: DaemonSet-managed pods (use --ignore-daemonsets to ignore): calicoopsmonitor-mfpqs, arachnia-agent-j56n8; pods not managed by ReplicationController, ReplicaSet, Job, DaemonSet or StatefulSet (use --force to override): kube-proxy-bjzw-prek8sredis-99-40
```



2、存在DaemonSet方式管理的Pod，需要设置`--ignore-daemonsets`参数忽略报错。

```
$ kubectl drain bjzw-prek8sredis-99-40 --force
node "bjzw-prek8sredis-99-40" already cordoned
error: unable to drain node "bjzw-prek8sredis-99-40", aborting command...

There are pending nodes to be drained:
 bjzw-prek8sredis-99-40
error: DaemonSet-managed pods (use --ignore-daemonsets to ignore): calicoopsmonitor-mfpqs, arachnia-agent-j56n8
```



# [4. kubectl drain](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/node/safely-drain-node.md#4-kubectl-drain)

```
$ kubectl drain --help
Drain node in preparation for maintenance.

The given node will be marked unschedulable to prevent new pods from arriving. 'drain' evicts the pods if the APIServer
supports eviction (http://kubernetes.io/docs/admin/disruptions/). Otherwise, it will use normal DELETE to delete the
pods. The 'drain' evicts or deletes all pods except mirror pods (which cannot be deleted through the API server).  If
there are DaemonSet-managed pods, drain will not proceed without --ignore-daemonsets, and regardless it will not delete
any DaemonSet-managed pods, because those pods would be immediately replaced by the DaemonSet controller, which ignores
unschedulable markings.  If there are any pods that are neither mirror pods nor managed by ReplicationController,
ReplicaSet, DaemonSet, StatefulSet or Job, then drain will not delete any pods unless you use --force.  --force will
also allow deletion to proceed if the managing resource of one or more pods is missing.

'drain' waits for graceful termination. You should not operate on the machine until the command completes.

When you are ready to put the node back into service, use kubectl uncordon, which will make the node schedulable again.

! http://kubernetes.io/images/docs/kubectl_drain.svg

Examples:
  # Drain node "foo", even if there are pods not managed by a ReplicationController, ReplicaSet, Job, DaemonSet or
StatefulSet on it.
  $ kubectl drain foo --force

  # As above, but abort if there are pods not managed by a ReplicationController, ReplicaSet, Job, DaemonSet or
StatefulSet, and use a grace period of 15 minutes.
  $ kubectl drain foo --grace-period=900

Options:
      --delete-local-data=false: Continue even if there are pods using emptyDir (local data that will be deleted when
the node is drained).
      --dry-run=false: If true, only print the object that would be sent, without sending it.
      --force=false: Continue even if there are pods not managed by a ReplicationController, ReplicaSet, Job, DaemonSet
or StatefulSet.
      --grace-period=-1: Period of time in seconds given to each pod to terminate gracefully. If negative, the default
value specified in the pod will be used.
      --ignore-daemonsets=false: Ignore DaemonSet-managed pods.
  -l, --selector='': Selector (label query) to filter on
      --timeout=0s: The length of time to wait before giving up, zero means infinite

Usage:
  kubectl drain NODE [options]

Use "kubectl options" for a list of global command-line options (applies to all commands).
```

# 指定Node调度与隔离

# [1. NodeSelector](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/node/nodeselector-and-taint.md#1-nodeselector)

## [1.1. 概念](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/node/nodeselector-and-taint.md#11-概念)

如果需要`限制Pod到指定的Node`上运行，则可以给Node打标签并给Pod配置NodeSelector。

## [1.2. 使用方式](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/node/nodeselector-and-taint.md#12-使用方式)

### [1.2.1. 给Node打标签](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/node/nodeselector-and-taint.md#121-给node打标签)

```
# get node的name
kubectl get nodes

# 设置Label
kubectl label nodes <node-name> <label-key>=<label-value>
# 例如
kubectl label nodes node-1 disktype=ssd

# 查看Node的Label
kubectl get nodes --show-labels

# 删除Node的label
kubectl label node <node-name> <label-key>-
```



### [1.2.2. 给Pod设置NodeSelector](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/node/nodeselector-and-taint.md#122-给pod设置nodeselector)

```
apiVersion: v1
kind: Pod
metadata:
  name: nginx
  labels:
    env: test
spec:
  containers:
  - name: nginx
    image: nginx
    imagePullPolicy: IfNotPresent
  nodeSelector:
    disktype: ssd    # 对应Node的Label
```



## [1.3. 亲和性（Affinity）和反亲和性（Anti-affinity）](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/node/nodeselector-and-taint.md#13-亲和性affinity和反亲和性anti-affinity)

> 待补充

# [2. Taint 和 Toleration](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/node/nodeselector-and-taint.md#2-taint-和-toleration)

## [2.1. 概念](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/node/nodeselector-and-taint.md#21-概念)

`nodeSelector`可以通过`打标签`的形式让Pod被调度到指定的Node上，`Taint `则相反，它使节点能够排斥一类特定的Pod，除非Pod被指定了`toleration`的标签。（`taint`即污点，Node被打上污点；只有容忍[toleration]这些污点的Pod才可能被调度到该Node）。

## [2.2. 使用方式](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/node/nodeselector-and-taint.md#22-使用方式)

### [2.2.1. kubectl taint](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/node/nodeselector-and-taint.md#221-kubectl-taint)

```
# 给节点增加一个taint，它的key是<key>，value是<value>，effect是NoSchedule。
kubectl taint nodes <node_name> <key>=<value>:NoSchedule
```



只有拥有和这个`taint`相匹配的`toleration`的pod才能够被分配到 `node_name` 这个节点。

例如，在 `PodSpec` 中定义 pod 的 toleration：

```
tolerations:
- key: "key"
  operator: "Equal"
  value: "value"
  effect: "NoSchedule"
```



```
tolerations:
- key: "key"
  operator: "Exists"
  effect: "NoSchedule"
```



### [2.2.2. 匹配规则：](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/node/nodeselector-and-taint.md#222-匹配规则)

一个 toleration 和一个 taint 相“匹配”是指它们有一样的 key 和 effect ，并且：

- 如果 `operator` 是 `Exists` （此时 toleration 不能指定 `value`）
- 如果 `operator` 是 `Equal` ，则它们的 `value` 应该相等

**特殊情况：**

- 如果一个 toleration 的 `key` 为空且 operator 为 `Exists` ，表示这个 toleration 与任意的 key 、 value 和 effect 都匹配，即这个 toleration 能容忍任意 taint。

  ```
  tolerations:
  - operator: "Exists"
  ```

  

- 如果一个 toleration 的 `effect` 为空，则 `key` 值与之相同的相匹配 taint 的 `effect` 可以是任意值。

  ```
  tolerations:
  - key: "key"
    operator: "Exists"
  ```

  

一个节点可以设置多个taint，一个pod也可以设置多个toleration。Kubernetes 处理多个 taint 和 toleration 的过程就像一个过滤器：从一个节点的所有 taint 开始遍历，过滤掉那些 pod 中存在与之相匹配的 toleration 的 taint。余下未被过滤的 taint 的 effect 值决定了 pod 是否会被分配到该节点，特别是以下情况：

- 如果未被过滤的 taint 中存在一个以上 effect 值为 `NoSchedule` 的 taint，则 Kubernetes 不会将 pod 分配到该节点。
- 如果未被过滤的 taint 中不存在 effect 值为 `NoSchedule` 的 taint，但是存在 effect 值为 `PreferNoSchedule` 的 taint，则 Kubernetes 会*尝试*将 pod 分配到该节点。
- 如果未被过滤的 taint 中存在一个以上 effect 值为 `NoExecute` 的 taint，则 Kubernetes 不会将 pod 分配到该节点（如果 pod 还未在节点上运行），或者将 pod 从该节点驱逐（如果 pod 已经在节点上运行）。

## [2.2.3. effect的类型](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/node/nodeselector-and-taint.md#223-effect的类型)

- `NoSchedule`：只有拥有和这个 taint 相匹配的 toleration 的 pod 才能够被分配到这个节点。

- `PreferNoSchedule`：系统会*尽量*避免将 pod 调度到存在其不能容忍 taint 的节点上，但这不是强制的。

- `NoExecute` ：任何不能忍受这个 taint 的 pod 都会马上被驱逐，任何可以忍受这个 taint 的 pod 都不会被驱逐。Pod可指定属性 `tolerationSeconds` 的值，表示pod 还能继续在节点上运行的时间。

  ```
  tolerations:
  - key: "key1"
    operator: "Equal"
    value: "value1"
    effect: "NoExecute"
    tolerationSeconds: 3600
  ```

  

## [2.3. 使用场景](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/node/nodeselector-and-taint.md#23-使用场景)

### [2.3.1. 专用节点](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/node/nodeselector-and-taint.md#231-专用节点)

```
kubectl taint nodes <nodename> dedicated=<groupName>:NoSchedule
```



先给Node添加taint，然后给Pod添加相对应的 toleration，则该Pod可调度到taint的Node，也可调度到其他节点。

如果想**让Pod只调度某些节点且某些节点只接受对应的Pod**，则需要在Node上添加`Label`（例如：`dedicated=groupName`），同时给Pod的`nodeSelector`添加对应的`Label`。

### [2.3.2. 特殊硬件节点](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/node/nodeselector-and-taint.md#232-特殊硬件节点)

如果某些节点配置了特殊硬件（例如CPU），希望不使用这些特殊硬件的Pod不被调度该Node，以便保留必要资源。即可给Node设置`taint`和`label`，同时给Pod设置`toleration`和`label`来使得这些Node专门被指定Pod使用。

```
# kubectl taint
kubectl taint nodes nodename special=true:NoSchedule 
# 或者
kubectl taint nodes nodename special=true:PreferNoSchedule
```



### [2.3.3. 基于taint驱逐](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/node/nodeselector-and-taint.md#233-基于taint驱逐)

effect 值 `NoExecute` ，它会影响已经在节点上运行的 pod，即根据策略对Pod进行驱逐。

- 如果 pod 不能忍受effect 值为 `NoExecute` 的 taint，那么 pod 将马上被驱逐
- 如果 pod 能够忍受effect 值为 `NoExecute` 的 taint，但是在 toleration 定义中没有指定 `tolerationSeconds`，则 pod 还会一直在这个节点上运行。
- 如果 pod 能够忍受effect 值为 `NoExecute` 的 taint，而且指定了 `tolerationSeconds`，则 pod 还能在这个节点上继续运行这个指定的时间长度。



# 镜像仓库配置

# 配置私有的镜像仓库

## [1. 镜像仓库的基本操作](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/registry/config-private-registry.md#1-镜像仓库的基本操作)

### [1.1. 登录镜像仓库](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/registry/config-private-registry.md#11-登录镜像仓库)

```
docker login -u <username> -p <password> <registry-addr>
```



### [1.2. 拉取镜像](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/registry/config-private-registry.md#12-拉取镜像)

```
docker pull https://registry.xxx.com/dev/nginx:latest
```



### [1.3. 推送镜像](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/registry/config-private-registry.md#13-推送镜像)

```
docker push https://registry.xxx.com/dev/nginx:latest
```



### [1.4. 重命名镜像](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/registry/config-private-registry.md#14-重命名镜像)

```
docker tag <old-image> <new-image>
```



## [2. docker.xxx.com镜像仓库](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/registry/config-private-registry.md#2-dockerxxxcom镜像仓库)

使用docker.xxx.com镜像仓库。

### [2.1. 所有节点配置insecure-registries](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/registry/config-private-registry.md#21-所有节点配置insecure-registries)

```
#cat /etc/docker/daemon.json
{
  "data-root": "/data/docker",
  "debug": false,
  "insecure-registries": [
	...
    "docker.xxx.com:8080"
  ],
  ...
}
```



### [2.2. 所有节点配置/var/lib/kubelet/config.json](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/registry/config-private-registry.md#22-所有节点配置varlibkubeletconfigjson)

具体参考：[configuring-nodes-to-authenticate-to-a-private-registry](https://kubernetes.io/docs/concepts/containers/images/#configuring-nodes-to-authenticate-to-a-private-registry)

1. 在某个节点登录docker.xxx.com:8080镜像仓库，会更新 $HOME/.docker/config.json
2. 检查$HOME/.docker/config.json是否有该镜像仓库的auth信息。

```
#cat ~/.docker/config.json
{
	"auths": {
		"docker.xxx.com:8080": {
			"auth": "<此处为凭证信息>"
		}
	},
	"HttpHeaders": {
		"User-Agent": "Docker-Client/18.09.9 (linux)"
	}
}
```



1. 将`$HOME/.docker/config.json`拷贝到所有的Node节点上的`/var/lib/kubelet/config.json`。

```
# 获取所有节点的IP
nodes=$(kubectl get nodes -o jsonpath='{range .items[*].status.addresses[?(@.type=="ExternalIP")]}{.address} {end}')
# 拷贝到所有节点
for n in $nodes; do scp ~/.docker/config.json root@$n:/var/lib/kubelet/config.json; done
```



### [2.3. 创建docker.xxx.com镜像的pod](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/registry/config-private-registry.md#23-创建dockerxxxcom镜像的pod)

指定镜像为：docker.xxx.com:8080/public/2048:latest

完整pod.yaml

```
apiVersion: apps/v1beta2
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "1"
  generation: 1
  labels:
    k8s-app: dockeroa-hub
    qcloud-app: dockeroa-hub
  name: dockeroa-hub
  namespace: test
spec:
  progressDeadlineSeconds: 600
  replicas: 3
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      k8s-app: dockeroa-hub
      qcloud-app: dockeroa-hub
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      labels:
        k8s-app: dockeroa-hub
        qcloud-app: dockeroa-hub
    spec:
      containers:
      - image: docker.xxx.com:8080/public/2048:latest
        imagePullPolicy: Always
        name: game
        resources:
          limits:
            cpu: 500m
            memory: 1Gi
          requests:
            cpu: 250m
            memory: 256Mi
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      nodeName: 192.168.1.1
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
```



查看pod状态

```
#kgpoowide -n game
NAME                                     READY   STATUS    RESTARTS   AGE     IP             NODE            NOMINATED NODE   READINESS GATES
docker-oa-757bbbddb5-h6j7m               1/1     Running   0          14m     192.168.2.51   192.168.1.1    <none>           <none>
docker-oa-757bbbddb5-jp5dw               1/1     Running   0          14m     192.168.1.32   192.168.1.2    <none>           <none>
docker-oa-757bbbddb5-nlw9f               1/1     Running   0          14m     192.168.0.43   192.168.1.3   <none>           <none>
```

# 拉取私有镜像



> 本文介绍通过pod指定 ImagePullSecrets来拉取私有镜像仓库的镜像

## [1. 创建secret](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/registry/ImagePullSecrets.md#1-创建secret)

secret是namespace级别的，创建时候需要指定namespace。

```
kubectl create secret docker-registry <name> --docker-server=DOCKER_REGISTRY_SERVER --docker-username=DOCKER_USER --docker-password=DOCKER_PASSWORD -n <NAMESPACE>
```



## [2. 添加ImagePullSecrets到serviceAccount](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/registry/ImagePullSecrets.md#2-添加imagepullsecrets到serviceaccount)

可以通过将ImagePullSecrets到serviceAccount的方式来自动给pod添加imagePullSecrets参数值。

serviceAccount同样是namespace级别，只对该namespace生效。

```
#kubectl get secrets -n dev
NAME                  TYPE                                  DATA   AGE
docker.xxxx.com         kubernetes.io/dockerconfigjson        1      6h23m
```



将ImagePullSecrets添加到serviceAccount对象中。

默认serviceAccount对象如下

```
#kubectl get serviceaccount default -n dev -o yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  creationTimestamp: "2020-02-27T03:30:38Z"
  name: default
  namespace: dev
  resourceVersion: "11651567"
  selfLink: /api/v1/namespaces/dev/serviceaccounts/default
  uid: 85bcdd31-5911-11ea-9429-6c92bf3b7c33
secrets:
- name: default-token-s7wfn
```



编辑或修改serviceAccount内容，增加imagePullSecrets字段。

```
imagePullSecrets:
- name: docker.xxxx.com
```



```
kubectl edit serviceaccount default -n dev
```

修改后内容为：

```
apiVersion: v1
kind: ServiceAccount
metadata:
  creationTimestamp: "2020-02-27T03:30:38Z"
  name: default
  namespace: dev
  resourceVersion: "11651567"
  selfLink: /api/v1/namespaces/dev/serviceaccounts/default
  uid: 85bcdd31-5911-11ea-9429-6c92bf3b7c33
secrets:
- name: default-token-s7wfn
imagePullSecrets:
- name: docker.xxxx.com
```



## [3. 创建带有imagePullSecrets的pod](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/registry/ImagePullSecrets.md#3-创建带有imagepullsecrets的pod)

如果已经执行了第二步操作，添加ImagePullSecrets到serviceAccount，则无需在pod中指定imagePullSecrets参数，默认会自动添加。

如果没有添加ImagePullSecrets到serviceAccount，则在pod中指定imagePullSecrets参数引用创建的镜像仓库的secret。

```
spec:
  imagePullSecrets:
  - name: docker.xxxx.com
```



## [4. 说明](https://github.com/huweihuang/kubernetes-notes/blob/master/operation/registry/ImagePullSecrets.md#4-说明)

由于secret和serviceaccount对象是对namespace级别生效，因此不同的namespace需要再次创建和更新这两个对象。该场景适合不同用户具有独立的镜像仓库的密码，可以通过该方式创建不同的镜像密码使用的secret来拉取不同的镜像部署。