# 日志收集项目架构设计及Kafka介绍
**项目背景**
每个业务系统都有日志，当系统出现问题时，需要通过日志信息来定位和解决问题。当系统机器比较少时，登陆到服务器上查看即可满足当系统机器规模巨大，登陆到机器上查看几乎不现实(分 布式的系统，一个系统部署在十几台机器上)
**解决方案**
把机器上的日志实时收集，统- -存储到中心系统。再对这些日志建立索引，通过搜索即可快速找到对应
的日志记录。通过提供- -个界面友好的web页面实现日志展示与检索。

**面临的问题**
实时日志量非常大，每天处理几十亿条。日志准实时收集，延迟控制在分钟级别。系统的架构设计能
够支持水平扩展。

**传统方案---ELK方案的问题**
●运维成本高，每增加一一个日志收集项，都需要手动修改配置。
●监控缺失， 无法准确获取logstash的状态。
●无法做到定制化开发与维护。

![image-20230424112342214](./assets/image-20230424112342214.png)

Etcd：分布式配置拉取与管理中间件
Log agent: 服务器日志收集器			Sys agent：系统配置信息收集器			Log transfer: 服务器日志拉取程序
Kafka: 日志存储中间件，高吞吐量的分布式队列(Linkin开发，apache顶级开源项目) 
ElasticSearch: 开源的搜索引擎，提供基于HTTP RESTful的web接口。
Kibana:开源的ES数据分析和可视化工具。
Hadoop: 分布式计算框架，能够对大量数据进行分布式处理的平台。
Storm: 一个免费并开源的分布式实时计算系统。
InfluxDB：实施数据库					grafana：系统配置web展示界面

**将学到的技能**
●服务端agent开发
●后端服务组件开发
●Kafka和zookeeper的使用
●ES和Kibana的使用
●etcd的使用



# Log Agent开发
## Log Agent工作流程：
1、读日志--使用tailf第三方库：

```sh
go install github.com/hpcloud/tail@latest
```

2、往kafka写日志--sarama第三方库：

```sh
go install github.com/Shopify/sarama@v1.19
```

3、zstd压缩算法下载安装：

```sh
go get github.com/DataDog/zstd
```

sarama v1.20之后的版本加入了zstd压缩算法，需要用到cgo，在Windows平台编译时会提示类似如下错误：

```shell
# github.com/DataDog/zstd
exec: "gcc":executable file not found in %PATH% //所以在Windows平台请使用v1.19版本的sarama。
```



# 环境配置

JDK的下载与安装
安装文件：[下载JDK](http://www.oracle.com/technetwork/java/javase/downloads/index.html )
[jdk镜像](https://repo.huaweicloud.com/java/jdk/)

安装完成后需要添加以下的环境变量（右键点击“我的电脑” -> "高级系统设置" -> "环境变量" ）：

```sh
	JAVA_HOME: F:\jdk11 (jdk的安装路径)
	Path: 在现有的值后面添加"; %JAVA_HOME%\bin"
```

打开cmd运行 "java -version" 查看当前系统Java的版本

# 2. 安装ZOOKEEPER

Kafka的运行依赖于Zookeeper，所以在运行Kafka之前我们需要安装并运行Zookeeper，安装zookeeper有两种方式，由于Kafka 0.5.x版本以上已经自带ZooKeper，不需要自己安装ZooKeeper。所以可以使用kafka自带的zoopeeper，也可以自己单独安装。下面介绍单独安装方式：
[下载安装zoopeeper](http://www.apache.org/dyn/closer.cgi/zookeeper/)

**解压文件**
打开zookeeper文件夹的conf目录，把zoo_sample.cfg重命名成zoo.cfg

**从文本编辑器里打开zoo.cfg**
把dataDir的值改成zoopeeper的文件夹目录下的data（zoopeeper数据存放地址）

添加如下系统变量：
	​ ZOOKEEPER_HOME: zookeeper目录
	​ Path: 在现有的值后面添加 ";%ZOOKEEPER_HOME%\bin;"
运行Zookeeper:  zkserver //打开cmd然后执行

# 3. 安装KAFKA
进入kafka的配置目录，编辑server.properties文件，修改log.dirs=XXX（XXX表示kafka日志路径），zookeeper.connect=XXX（默认是localhost：2181，如修改了上一步的Zookeeper的端口，需要在这里修改）

kafka会自动默认使用9092端口，如需变动，可以修改listeners=PLAINTEXT://:XXXX（将XXXX换成变动后的端口）
打开kafka目录，进入bin/windows目录下，shift+鼠标右键选择打开命令窗口（也可以直接通过cmd cd 文件目录的方式进入）

## 启动zoopeeper
```bash
bin\windows\zookeeper-server-start.bat .\config\zookeeper.properties# 启动kafka
bin\windows\kafka-server-start.bat .\config\server.properties

.\kafka-console-consumer.bat --bootstrap-server=127.0.0.1:9092 --topic=web_log --from-beginning //消费日志，打印在终端
```



# **项目总结**

1、项目的架构(图)

2、为什么不用ELK

3、logAgent里面如何保证日志不丢/重启之后继续收集日志(记录读取文件的offset)

4、kafka课上整理的那一些

5、etcd的watch的原理6.es相关知识点
